{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "tracker = None\n",
    "bbox = None\n",
    "tracking = False\n",
    "\n",
    "# Optical flow parameters\n",
    "feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Tracking variables\n",
    "prev_frame = None\n",
    "prev_pts = None\n",
    "tracking_history = []  # Store recent tracking positions\n",
    "\n",
    "# Select ROI\n",
    "ret, frame = cap.read()\n",
    "cv2.putText(frame, \"Select ROI & press ENTER\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "bbox = cv2.selectROI(\"Select ROI\", frame, fromCenter=False, showCrosshair=True)\n",
    "cv2.destroyWindow(\"Select ROI\")\n",
    "\n",
    "if bbox != (0, 0, 0, 0):\n",
    "    # Initialize CSRT tracker\n",
    "    tracker = cv2.TrackerCSRT_create()\n",
    "    tracker.init(frame, bbox)\n",
    "    tracking = True\n",
    "    \n",
    "    # Initialize optical flow\n",
    "    prev_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    x, y, w, h = map(int, bbox)\n",
    "    roi = prev_frame[y:y+h, x:x+w]\n",
    "    prev_pts = cv2.goodFeaturesToTrack(roi, mask=None, **feature_params)\n",
    "    if prev_pts is not None:\n",
    "        prev_pts = prev_pts + np.array([x, y], dtype=np.float32)  # Adjust coordinates to global frame\n",
    "\n",
    "def update_tracker_with_optical_flow(frame, gray_frame):\n",
    "    global prev_frame, prev_pts, bbox\n",
    "    \n",
    "    if prev_frame is None or prev_pts is None or len(prev_pts) < 5:\n",
    "        return False, bbox\n",
    "    \n",
    "    # Calculate optical flow\n",
    "    next_pts, status, _ = cv2.calcOpticalFlowPyrLK(prev_frame, gray_frame, prev_pts, None, **lk_params)\n",
    "    \n",
    "    # Filter good points\n",
    "    if next_pts is not None:\n",
    "        good_new = next_pts[status == 1]\n",
    "        good_old = prev_pts[status == 1]\n",
    "        \n",
    "        if len(good_new) > 5:  # Enough points to estimate movement\n",
    "            # Calculate bounding box movement\n",
    "            movement = np.mean(good_new - good_old, axis=0)\n",
    "            x, y, w, h = bbox\n",
    "            \n",
    "            # Update bounding box position\n",
    "            new_x = x + movement[0]\n",
    "            new_y = y + movement[1]\n",
    "            \n",
    "            # Update previous points for next iteration\n",
    "            prev_pts = good_new.reshape(-1, 1, 2)\n",
    "            prev_frame = gray_frame.copy()\n",
    "            \n",
    "            # Update bbox\n",
    "            bbox = (new_x, new_y, w, h)\n",
    "            return True, bbox\n",
    "    \n",
    "    # Not enough points to track\n",
    "    return False, bbox\n",
    "\n",
    "# Main loop\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    if tracking and tracker:\n",
    "        # 1. Try CSRT tracker\n",
    "        tracking_success, new_bbox = tracker.update(frame)\n",
    "        \n",
    "        # 2. Apply optical flow\n",
    "        of_success, of_bbox = update_tracker_with_optical_flow(frame, gray_frame)\n",
    "            \n",
    "        # Decide which result to use\n",
    "        if tracking_success and of_success:\n",
    "            # Blend CSRT and optical flow results (weighted average)\n",
    "            csrt_weight = 0.7\n",
    "            of_weight = 0.3\n",
    "            x1, y1, w1, h1 = new_bbox\n",
    "            x2, y2, w2, h2 = of_bbox\n",
    "            \n",
    "            blended_x = x1 * csrt_weight + x2 * of_weight\n",
    "            blended_y = y1 * csrt_weight + y2 * of_weight\n",
    "            bbox = (blended_x, blended_y, w1, h1)  # Keep original width/height\n",
    "            \n",
    "            # Update optical flow points occasionally for long-term stability\n",
    "            if len(tracking_history) % 10 == 0:\n",
    "                x, y, w, h = map(int, bbox)\n",
    "                roi = gray_frame[max(0, y):min(frame.shape[0], y+h), \n",
    "                               max(0, x):min(frame.shape[1], x+w)]\n",
    "                if roi.size > 0:\n",
    "                    pts = cv2.goodFeaturesToTrack(roi, mask=None, **feature_params)\n",
    "                    if pts is not None and pts.size > 0:\n",
    "                        prev_pts = pts + np.array([x, y], dtype=np.float32)\n",
    "                        prev_frame = gray_frame.copy()\n",
    "        elif tracking_success:\n",
    "            bbox = new_bbox\n",
    "        elif of_success:\n",
    "            bbox = of_bbox\n",
    "        \n",
    "        # Store tracking history\n",
    "        if tracking_success or of_success:\n",
    "            x, y, w, h = map(float, bbox)\n",
    "            center_x, center_y = x + w/2, y + h/2\n",
    "            tracking_history.append((center_x, center_y))\n",
    "            if len(tracking_history) > 30:  # Keep last 30 positions\n",
    "                tracking_history.pop(0)\n",
    "            \n",
    "            print(\"Tracking: Success\")\n",
    "        else:\n",
    "            print(\"Tracking: Lost\")\n",
    "        \n",
    "    # Draw tracking information on frame\n",
    "    if bbox is not None:\n",
    "        x, y, w, h = map(int, bbox)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw tracking history\n",
    "        if len(tracking_history) > 1:\n",
    "            for i in range(1, len(tracking_history)):\n",
    "                pt1 = tuple(map(int, tracking_history[i-1]))\n",
    "                pt2 = tuple(map(int, tracking_history[i]))\n",
    "                cv2.line(frame, pt1, pt2, (0, 0, 255), 1)\n",
    "    \n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    "    \n",
    "    # Exit on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Clean up\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gemy2\\AppData\\Local\\Temp\\ipykernel_24648\\3337927674.py:107: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  x, y, w, h = map(int, bbox)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "tracker = None\n",
    "bbox = None\n",
    "tracking = False\n",
    "\n",
    "# Optical flow parameters\n",
    "feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Kalman Filter setup\n",
    "kalman = cv2.KalmanFilter(4, 2)  # 4 state variables (x, y, vx, vy), 2 measurement variables (x, y)\n",
    "kalman.transitionMatrix = np.array([[1, 0, 1, 0],  [0, 1, 0, 1],  [0, 0, 1, 0],  [0, 0, 0, 1]], np.float32)\n",
    "kalman.measurementMatrix = np.array([[1, 0, 0, 0],  [0, 1, 0, 0]], np.float32)\n",
    "kalman.processNoiseCov = np.eye(4, dtype=np.float32) * 0.03\n",
    "kalman.measurementNoiseCov = np.eye(2, dtype=np.float32) * 0.3\n",
    "kalman.statePre = np.zeros((4, 1), np.float32)\n",
    "kalman.statePost = np.zeros((4, 1), np.float32)\n",
    "\n",
    "# Tracking variables\n",
    "prev_frame = None\n",
    "prev_pts = None\n",
    "\n",
    "# Select ROI\n",
    "ret, frame = cap.read()\n",
    "cv2.putText(frame, \"Select ROI & press ENTER\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "bbox = cv2.selectROI(\"Select ROI\", frame, fromCenter=False, showCrosshair=True)\n",
    "cv2.destroyWindow(\"Select ROI\")\n",
    "\n",
    "if bbox != (0, 0, 0, 0):\n",
    "    tracker = cv2.TrackerCSRT_create()\n",
    "    tracker.init(frame, bbox)\n",
    "    tracking = True\n",
    "    prev_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    x, y, w, h = map(int, bbox)\n",
    "    roi = prev_frame[y:y+h, x:x+w]\n",
    "    prev_pts = cv2.goodFeaturesToTrack(roi, mask=None, **feature_params)\n",
    "    if prev_pts is not None:\n",
    "        prev_pts = prev_pts + np.array([x, y], dtype=np.float32)\n",
    "    \n",
    "    # Initialize Kalman Filter\n",
    "    kalman.statePre[:2] = np.array([[x + w / 2], [y + h / 2]], np.float32)\n",
    "    kalman.statePost = kalman.statePre.copy()\n",
    "\n",
    "def update_tracker_with_optical_flow(frame, gray_frame):\n",
    "    global prev_frame, prev_pts, bbox\n",
    "    if prev_frame is None or prev_pts is None or len(prev_pts) < 5:\n",
    "        return False, bbox\n",
    "    \n",
    "    next_pts, status, _ = cv2.calcOpticalFlowPyrLK(prev_frame, gray_frame, prev_pts, None, **lk_params)\n",
    "    if next_pts is not None:\n",
    "        good_new = next_pts[status == 1]\n",
    "        good_old = prev_pts[status == 1]\n",
    "        if len(good_new) > 5:\n",
    "            movement = np.mean(good_new - good_old, axis=0)\n",
    "            x, y, w, h = bbox\n",
    "            new_x = x + movement[0]\n",
    "            new_y = y + movement[1]\n",
    "            prev_pts = good_new.reshape(-1, 1, 2)\n",
    "            prev_frame = gray_frame.copy()\n",
    "            bbox = (new_x, new_y, w, h)\n",
    "            return True, bbox\n",
    "    return False, bbox\n",
    "\n",
    "# Main loop\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    if tracking:\n",
    "        # Predict next position using Kalman Filter\n",
    "        prediction = kalman.predict()\n",
    "        pred_x, pred_y = prediction[0], prediction[1]\n",
    "        \n",
    "        # Update tracker\n",
    "        tracking_success, new_bbox = tracker.update(frame)\n",
    "        of_success, of_bbox = update_tracker_with_optical_flow(frame, gray_frame)\n",
    "        \n",
    "        if tracking_success and of_success:\n",
    "            x1, y1, w1, h1 = new_bbox\n",
    "            x2, y2, w2, h2 = of_bbox\n",
    "            measured_x = (x1 + x2) / 2\n",
    "            measured_y = (y1 + y2) / 2\n",
    "        elif tracking_success:\n",
    "            measured_x, measured_y = new_bbox[0], new_bbox[1]\n",
    "        elif of_success:\n",
    "            measured_x, measured_y = of_bbox[0], of_bbox[1]\n",
    "        else:\n",
    "            measured_x, measured_y = pred_x, pred_y\n",
    "        \n",
    "        measurement = np.array([[np.float32(measured_x)], [np.float32(measured_y)]])\n",
    "        kalman.correct(measurement)\n",
    "        bbox = (measured_x, measured_y, bbox[2], bbox[3])\n",
    "        \n",
    "        x, y, w, h = map(int, bbox)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    \n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbox: (251, 362, 88, 63)\n",
      "roi: [[137 135 134 ... 119 116 110]\n",
      " [138 137 136 ... 114 115 115]\n",
      " [138 137 137 ... 111 111 110]\n",
      " ...\n",
      " [119 118 116 ... 170 173 177]\n",
      " [117 116 115 ... 169 172 175]\n",
      " [117 115 113 ... 170 171 173]]\n",
      "prev_pts: [[[305. 418.]]\n",
      "\n",
      " [[316. 368.]]\n",
      "\n",
      " [[327. 403.]]\n",
      "\n",
      " [[298. 416.]]\n",
      "\n",
      " [[312. 420.]]\n",
      "\n",
      " [[290. 413.]]]\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "tracker = None\n",
    "bbox = None\n",
    "tracking = False\n",
    "\n",
    "# Optical flow parameters\n",
    "feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Tracking variables\n",
    "prev_frame = None\n",
    "prev_pts = None\n",
    "tracking_history = []  # Store recent tracking positions\n",
    "\n",
    "# Select ROI\n",
    "ret, frame = cap.read()\n",
    "cv2.putText(frame, \"Select ROI & press ENTER\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "bbox = cv2.selectROI(\"Select ROI\", frame, fromCenter=False, showCrosshair=True)\n",
    "cv2.destroyWindow(\"Select ROI\")\n",
    "\n",
    "if bbox != (0, 0, 0, 0):\n",
    "    # Initialize CSRT tracker\n",
    "    tracker = cv2.TrackerCSRT_create()\n",
    "    tracker.init(frame, bbox)\n",
    "    tracking = True\n",
    "    \n",
    "    # Initialize optical flow\n",
    "    prev_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    x, y, w, h = map(int, bbox)\n",
    "    roi = prev_frame[y:y+h, x:x+w]\n",
    "    prev_pts = cv2.goodFeaturesToTrack(roi, mask=None, **feature_params)\n",
    "    if prev_pts is not None:\n",
    "        prev_pts = prev_pts + np.array([x, y], dtype=np.float32)  # Adjust coordinates to global frame\n",
    "    print('bbox:', bbox)\n",
    "    print('roi:', roi)\n",
    "    print('prev_pts:', prev_pts)\n",
    "\n",
    "def update_tracker_with_optical_flow(frame, gray_frame):\n",
    "    global prev_frame, prev_pts, bbox\n",
    "    \n",
    "    if prev_frame is None or prev_pts is None or len(prev_pts) < 5:\n",
    "        return False, bbox\n",
    "    \n",
    "    # Calculate optical flow\n",
    "    next_pts, status, _ = cv2.calcOpticalFlowPyrLK(prev_frame, gray_frame, prev_pts, None, **lk_params)\n",
    "    \n",
    "    # Filter good points\n",
    "    if next_pts is not None:\n",
    "        good_new = next_pts[status == 1]\n",
    "        good_old = prev_pts[status == 1]\n",
    "        \n",
    "        if len(good_new) > 5:  # Enough points to estimate movement\n",
    "            # Calculate bounding box movement\n",
    "            movement = np.mean(good_new - good_old, axis=0)\n",
    "            x, y, w, h = bbox\n",
    "            \n",
    "            # Update bounding box position\n",
    "            new_x = x + movement[0]\n",
    "            new_y = y + movement[1]\n",
    "            \n",
    "            # Update previous points for next iteration\n",
    "            prev_pts = good_new.reshape(-1, 1, 2)\n",
    "            prev_frame = gray_frame.copy()\n",
    "            \n",
    "            # Update bbox\n",
    "            bbox = (new_x, new_y, w, h)\n",
    "            return True, bbox\n",
    "    \n",
    "    # Not enough points to track\n",
    "    return False, bbox\n",
    "\n",
    "# Main loop\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    if tracking and tracker:\n",
    "        # 1. Try CSRT tracker\n",
    "        tracking_success, new_bbox = tracker.update(frame)\n",
    "        \n",
    "        # 2. Apply optical flow\n",
    "        of_success, of_bbox = update_tracker_with_optical_flow(frame, gray_frame)\n",
    "            \n",
    "        # Decide which result to use\n",
    "        if tracking_success and of_success:\n",
    "            # Blend CSRT and optical flow results (weighted average)\n",
    "            csrt_weight = 0.7\n",
    "            of_weight = 0.3\n",
    "            x1, y1, w1, h1 = new_bbox\n",
    "            x2, y2, w2, h2 = of_bbox\n",
    "            \n",
    "            blended_x = x1 * csrt_weight + x2 * of_weight\n",
    "            blended_y = y1 * csrt_weight + y2 * of_weight\n",
    "            bbox = (blended_x, blended_y, w1, h1)  # Keep original width/height\n",
    "            \n",
    "            # Update optical flow points occasionally for long-term stability\n",
    "            if len(tracking_history) % 10 == 0:\n",
    "                x, y, w, h = map(int, bbox)\n",
    "                roi = gray_frame[max(0, y):min(frame.shape[0], y+h), max(0, x):min(frame.shape[1], x+w)]\n",
    "                if roi.size > 0:\n",
    "                    pts = cv2.goodFeaturesToTrack(roi, mask=None, **feature_params)\n",
    "                    if pts is not None and pts.size > 0:\n",
    "                        prev_pts = pts + np.array([x, y], dtype=np.float32)\n",
    "                        prev_frame = gray_frame.copy()\n",
    "        elif tracking_success:\n",
    "            bbox = new_bbox\n",
    "        elif of_success:\n",
    "            bbox = of_bbox\n",
    "        \n",
    "        # Store tracking history\n",
    "        if tracking_success or of_success:\n",
    "            x, y, w, h = map(float, bbox)\n",
    "            center_x, center_y = x + w/2, y + h/2\n",
    "            tracking_history.append((center_x, center_y))\n",
    "            if len(tracking_history) > 30:  # Keep last 30 positions\n",
    "                tracking_history.pop(0)\n",
    "            \n",
    "            print(\"Tracking: Success\")\n",
    "        else:\n",
    "            print(\"Tracking: Lost\")\n",
    "        \n",
    "    # Draw tracking information on frame\n",
    "    if bbox is not None:\n",
    "        x, y, w, h = map(int, bbox)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw tracking history\n",
    "        if len(tracking_history) > 1:\n",
    "            for i in range(1, len(tracking_history)):\n",
    "                pt1 = tuple(map(int, tracking_history[i-1]))\n",
    "                pt2 = tuple(map(int, tracking_history[i]))\n",
    "                cv2.line(frame, pt1, pt2, (0, 0, 255), 1)\n",
    "    \n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    "    \n",
    "    # Exit on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Clean up\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize tracking variables\n",
    "tracker = None\n",
    "bbox = None\n",
    "tracking = False\n",
    "\n",
    "# Optical flow parameters\n",
    "feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=2, \n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Tracking variables\n",
    "prev_frame = None\n",
    "prev_pts = None\n",
    "tracking_history = []  # Store recent tracking positions\n",
    "\n",
    "# Kalman Filter setup\n",
    "kalman = cv2.KalmanFilter(4, 2)  # 4 state variables (x, y, dx, dy), 2 measurement variables (x, y)\n",
    "kalman.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)  # Measurement matrix\n",
    "kalman.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)  # State transition matrix\n",
    "kalman.processNoiseCov = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32) * 0.03  # Process noise\n",
    "kalman.measurementNoiseCov = np.array([[1, 0], [0, 1]], np.float32) * 0.1  # Measurement noise\n",
    "\n",
    "# Select ROI\n",
    "ret, frame = cap.read()\n",
    "cv2.putText(frame, \"Select ROI & press ENTER\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "bbox = cv2.selectROI(\"Select ROI\", frame, fromCenter=False, showCrosshair=True)\n",
    "cv2.destroyWindow(\"Select ROI\")\n",
    "\n",
    "if bbox != (0, 0, 0, 0):\n",
    "    # Initialize CSRT tracker\n",
    "    tracker = cv2.TrackerCSRT_create()\n",
    "    tracker.init(frame, bbox)\n",
    "    tracking = True\n",
    "    \n",
    "    # Initialize optical flow\n",
    "    prev_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    x, y, w, h = map(int, bbox)\n",
    "    roi = prev_frame[y:y+h, x:x+w]\n",
    "    prev_pts = cv2.goodFeaturesToTrack(roi, mask=None, **feature_params)\n",
    "    if prev_pts is not None:\n",
    "        prev_pts = prev_pts + np.array([x, y], dtype=np.float32)  # Adjust coordinates to global frame\n",
    "    \n",
    "    # Initialize Kalman filter with current position\n",
    "    center_x, center_y = x + w/2, y + h/2\n",
    "    kalman.statePre = np.array([[center_x], [center_y], [0], [0]], np.float32)\n",
    "    kalman.statePost = np.array([[center_x], [center_y], [0], [0]], np.float32)\n",
    "\n",
    "def update_tracker_with_optical_flow(frame, gray_frame):\n",
    "    global prev_frame, prev_pts, bbox\n",
    "    \n",
    "    if prev_frame is None or prev_pts is None or len(prev_pts) < 5:\n",
    "        return False, bbox\n",
    "    \n",
    "    # Calculate optical flow\n",
    "    next_pts, status, _ = cv2.calcOpticalFlowPyrLK(prev_frame, gray_frame, prev_pts, None, **lk_params)\n",
    "    \n",
    "    # Filter good points\n",
    "    if next_pts is not None:\n",
    "        good_new = next_pts[status == 1]\n",
    "        good_old = prev_pts[status == 1]\n",
    "        \n",
    "        if len(good_new) > 5:  # Enough points to estimate movement\n",
    "            # Calculate bounding box movement\n",
    "            movement = np.mean(good_new - good_old, axis=0)\n",
    "            x, y, w, h = bbox\n",
    "            \n",
    "            # Update bounding box position\n",
    "            new_x = x + movement[0]\n",
    "            new_y = y + movement[1]\n",
    "            \n",
    "            # Update previous points for next iteration\n",
    "            prev_pts = good_new.reshape(-1, 1, 2)\n",
    "            prev_frame = gray_frame.copy()\n",
    "            \n",
    "            # Update bbox\n",
    "            bbox = (new_x, new_y, w, h)\n",
    "            return True, bbox\n",
    "    \n",
    "    # Not enough points to track\n",
    "    return False, bbox\n",
    "\n",
    "def apply_kalman_filter(bbox):\n",
    "    # Predict\n",
    "    prediction = kalman.predict()\n",
    "    \n",
    "    # Get the current center from bbox\n",
    "    x, y, w, h = bbox\n",
    "    center_x, center_y = x + w/2, y + h/2\n",
    "    \n",
    "    # Correct with measurement\n",
    "    measurement = np.array([[center_x], [center_y]], np.float32)\n",
    "    kalman.correct(measurement)\n",
    "    \n",
    "    # Get the filtered position\n",
    "    filtered_x = kalman.statePost[0][0]\n",
    "    filtered_y = kalman.statePost[1][0]\n",
    "    \n",
    "    # Calculate the new bbox position\n",
    "    new_x = filtered_x - w/2\n",
    "    new_y = filtered_y - h/2\n",
    "    \n",
    "    return (new_x, new_y, w, h)\n",
    "\n",
    "# Main loop\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    if tracking and tracker:\n",
    "        # 1. Try CSRT tracker\n",
    "        tracking_success, new_bbox = tracker.update(frame)\n",
    "        \n",
    "        # 2. Apply optical flow\n",
    "        of_success, of_bbox = update_tracker_with_optical_flow(frame, gray_frame)\n",
    "            \n",
    "        # Decide which result to use\n",
    "        if tracking_success and of_success:\n",
    "            # Blend CSRT and optical flow results (weighted average)\n",
    "            csrt_weight = 0.7\n",
    "            of_weight = 0.3\n",
    "            x1, y1, w1, h1 = new_bbox\n",
    "            x2, y2, w2, h2 = of_bbox\n",
    "            \n",
    "            blended_x = x1 * csrt_weight + x2 * of_weight\n",
    "            blended_y = y1 * csrt_weight + y2 * of_weight\n",
    "            bbox = (blended_x, blended_y, w1, h1)  # Keep original width/height\n",
    "            \n",
    "            # Apply Kalman filter to smooth the result\n",
    "            bbox = apply_kalman_filter(bbox)\n",
    "            \n",
    "            # Update optical flow points occasionally for long-term stability\n",
    "            if len(tracking_history) % 10 == 0:\n",
    "                x, y, w, h = map(int, bbox)\n",
    "                roi = gray_frame[max(0, y):min(frame.shape[0], y+h), \n",
    "                               max(0, x):min(frame.shape[1], x+w)]\n",
    "                if roi.size > 0:\n",
    "                    pts = cv2.goodFeaturesToTrack(roi, mask=None, **feature_params)\n",
    "                    if pts is not None and pts.size > 0:\n",
    "                        prev_pts = pts + np.array([x, y], dtype=np.float32)\n",
    "                        prev_frame = gray_frame.copy()\n",
    "        elif tracking_success:\n",
    "            bbox = new_bbox\n",
    "            # Apply Kalman filter to smooth the result\n",
    "            bbox = apply_kalman_filter(bbox)\n",
    "        elif of_success:\n",
    "            bbox = of_bbox\n",
    "            # Apply Kalman filter to smooth the result\n",
    "            bbox = apply_kalman_filter(bbox)\n",
    "        \n",
    "        # Store tracking history\n",
    "        if tracking_success or of_success:\n",
    "            x, y, w, h = map(float, bbox)\n",
    "            center_x, center_y = x + w/2, y + h/2\n",
    "            tracking_history.append((center_x, center_y))\n",
    "            if len(tracking_history) > 30:  # Keep last 30 positions\n",
    "                tracking_history.pop(0)\n",
    "            \n",
    "            print(\"Tracking: Success\")\n",
    "        else:\n",
    "            print(\"Tracking: Lost\")\n",
    "        \n",
    "    # Draw tracking information on frame\n",
    "    if bbox is not None:\n",
    "        x, y, w, h = map(int, bbox)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw tracking history\n",
    "        if len(tracking_history) > 1:\n",
    "            for i in range(1, len(tracking_history)):\n",
    "                pt1 = tuple(map(int, tracking_history[i-1]))\n",
    "                pt2 = tuple(map(int, tracking_history[i]))\n",
    "                cv2.line(frame, pt1, pt2, (0, 0, 255), 1)\n",
    "    \n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    "    \n",
    "    # Exit on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Clean up\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSRT Tracker & Optical Flow & Kalman Filter  & Tracking History\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "tracker = cv2.TrackerCSRT_create()\n",
    "ret, frame = cap.read()\n",
    "bbox = cv2.selectROI(\"Select Object\", frame, False)\n",
    "tracker.init(frame, bbox)\n",
    "\n",
    "prev_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "kalman = cv2.KalmanFilter(4, 2)\n",
    "kalman.measurementMatrix = np.array([[1, 0, 0, 0],[0, 1, 0, 0]], np.float32)\n",
    "kalman.transitionMatrix = np.array([[1, 0, 1, 0],[0, 1, 0, 1],[0, 0, 1, 0],[0, 0, 0, 1]], np.float32)\n",
    "kalman.processNoiseCov = np.eye(4, dtype=np.float32) * 0.03\n",
    "\n",
    "\n",
    "tracking_history = deque(maxlen=10)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    success, bbox = tracker.update(frame)\n",
    "\n",
    "    if success:\n",
    "        x, y, w, h = [int(v) for v in bbox]\n",
    "        center_x, center_y = x + w // 2, y + h // 2\n",
    "\n",
    "        measurement = np.array([[np.float32(center_x)], [np.float32(center_y)]])\n",
    "        kalman.correct(measurement)\n",
    "\n",
    "        tracking_history.append((center_x, center_y, w, h))\n",
    "\n",
    "    else:\n",
    "        \n",
    "        if len(tracking_history) > 1:\n",
    "            # الحصول على آخر موقعين معروفين\n",
    "            p0 = np.array([[tracking_history[-2][:2]]], dtype=np.float32)\n",
    "            p1, st, err = cv2.calcOpticalFlowPyrLK(prev_gray, gray, p0, None)\n",
    "\n",
    "            if p1 is not None and st[0] == 1:\n",
    "                # Optical Flow\n",
    "                pred_x, pred_y = int(p1[0][0][0]), int(p1[0][0][1])\n",
    "            else:\n",
    "                #  Kalman Filter \n",
    "                prediction = kalman.predict()\n",
    "                pred_x, pred_y = int(prediction[0]), int(prediction[1])\n",
    "\n",
    "            # إعادة إنشاء التراكر عند الموقع المتوقع\n",
    "            bbox = (pred_x - w // 2, pred_y - h // 2, w, h)\n",
    "            tracker = cv2.TrackerCSRT_create()\n",
    "            tracker.init(frame, bbox)\n",
    "\n",
    "    prev_gray = gray.copy()\n",
    "\n",
    "    if len(tracking_history) > 0:\n",
    "        last_x, last_y, last_w, last_h = tracking_history[-1]\n",
    "        cv2.rectangle(frame, (last_x - last_w // 2, last_y - last_h // 2),\n",
    "                      (last_x + last_w // 2, last_y + last_h // 2), (0, 255, 0), 2)\n",
    "\n",
    "    for i in range(1, len(tracking_history)):\n",
    "        cv2.line(frame, tracking_history[i - 1][:2], tracking_history[i][:2], (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gemy2\\AppData\\Local\\Temp\\ipykernel_4752\\3232810261.py:76: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  pred_x, pred_y = int(prediction[0]), int(prediction[1])\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Read first frame\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Let user select ROI (Region of Interest)\n",
    "bbox = cv2.selectROI(\"Select Object to Track\", frame, False)\n",
    "cv2.destroyWindow(\"Select Object to Track\")\n",
    "\n",
    "# Initialize the CSRT tracker\n",
    "tracker = cv2.legacy.TrackerCSRT_create()\n",
    "tracker.init(frame, bbox)\n",
    "\n",
    "# Initialize variables for tracking\n",
    "tracking_active = True\n",
    "bbox_history = deque(maxlen=10)  # Store last 10 positions\n",
    "bbox_history.append(bbox)\n",
    "\n",
    "# Initialize Kalman filter\n",
    "kalman = cv2.KalmanFilter(4, 2)\n",
    "kalman.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)\n",
    "kalman.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)\n",
    "kalman.processNoiseCov = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32) * 0.03\n",
    "\n",
    "# Initialize variables for optical flow\n",
    "old_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "old_points = None\n",
    "    \n",
    "while True:\n",
    "    # Read a new frame\n",
    "    ret, frame = cap.read()\n",
    "        \n",
    "    # Create a copy of the frame for visualization\n",
    "    frame_display = frame.copy()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 1. CSRT Tracker\n",
    "    if tracking_active:\n",
    "        success, bbox = tracker.update(frame)\n",
    "        \n",
    "        # If tracking is successful, update history and Kalman filter\n",
    "        if success:\n",
    "            x, y, w, h = [int(v) for v in bbox]\n",
    "            bbox_history.append((x, y, w, h))\n",
    "            \n",
    "            # Kalman measurement update\n",
    "            kalman.correct(np.array([[x + w/2], [y + h/2]], np.float32))\n",
    "            \n",
    "            # Save points for optical flow\n",
    "            if old_points is None or len(old_points) < 10:\n",
    "                # Define region for feature detection\n",
    "                roi = old_gray[y:y+h, x:x+w]\n",
    "                # Find good features to track\n",
    "                try:\n",
    "                    points = cv2.goodFeaturesToTrack(roi, 100, 0.01, 10)\n",
    "                    if points is not None:\n",
    "                        old_points = points + np.array([x, y], np.float32)\n",
    "                except cv2.error:\n",
    "                    old_points = None\n",
    "            \n",
    "            # Draw the bbox\n",
    "            cv2.rectangle(frame_display, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame_display, \"Tracking\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        else:\n",
    "            tracking_active = False\n",
    "            \n",
    "    # 2. If tracking fails, use prediction and attempt reinitialization\n",
    "    if not tracking_active:\n",
    "        # Predict using Kalman filter\n",
    "        prediction = kalman.predict()\n",
    "        pred_x, pred_y = int(prediction[0]), int(prediction[1])\n",
    "        \n",
    "        # Use the last known size from history\n",
    "        if bbox_history:\n",
    "            last_x, last_y, last_w, last_h = bbox_history[-1]\n",
    "            predicted_bbox = (pred_x - last_w//2, pred_y - last_h//2, last_w, last_h)\n",
    "            \n",
    "            # Attempt to reinitialize tracker at the predicted position\n",
    "            tracker = cv2.legacy.TrackerCSRT_create()\n",
    "            success = tracker.init(frame, predicted_bbox)\n",
    "            if success:\n",
    "                tracking_active = True\n",
    "                bbox = predicted_bbox\n",
    "            \n",
    "            # Draw the predicted position\n",
    "            cv2.rectangle(frame_display, (pred_x - last_w//2, pred_y - last_h//2), \n",
    "                            (pred_x + last_w//2, pred_y + last_h//2), (0, 0, 255), 2)\n",
    "            cv2.putText(frame_display, \"Predicted\", (pred_x - last_w//2, pred_y - last_h//2 - 10), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    \n",
    "    # 3. Lucas-Kanade Optical Flow for additional tracking\n",
    "    if old_points is not None and len(old_points) > 0:\n",
    "        new_points, status, _ = cv2.calcOpticalFlowPyrLK(old_gray, gray, old_points, None)\n",
    "        \n",
    "        if new_points is not None:\n",
    "            # Keep only good points\n",
    "            good_new = new_points[status == 1]\n",
    "            good_old = old_points[status == 1]\n",
    "            \n",
    "            # If we have enough points, use them to refine the bbox\n",
    "            if len(good_new) > 5 and tracking_active:\n",
    "                # Calculate the median shift\n",
    "                shifts = good_new - good_old\n",
    "                if len(shifts) > 0:\n",
    "                    median_shift = np.median(shifts, axis=0)\n",
    "                    x, y, w, h = [int(v) for v in bbox]\n",
    "                    \n",
    "                    # Apply the shift to the current bbox\n",
    "                    shifted_bbox = (x + int(median_shift[0]), y + int(median_shift[1]), w, h)\n",
    "                    \n",
    "                    # Update Kalman with optical flow information\n",
    "                    center_x = shifted_bbox[0] + shifted_bbox[2]//2\n",
    "                    center_y = shifted_bbox[1] + shifted_bbox[3]//2\n",
    "                    kalman.correct(np.array([[center_x], [center_y]], np.float32))\n",
    "                \n",
    "            # Draw optical flow tracks\n",
    "            for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "                a, b = new.ravel().astype(int)\n",
    "                c, d = old.ravel().astype(int)\n",
    "                cv2.line(frame_display, (a, b), (c, d), (0, 255, 255), 2)\n",
    "                cv2.circle(frame_display, (a, b), 3, (0, 255, 255), -1)\n",
    "            \n",
    "            # Update old_points for next frame\n",
    "            old_points = good_new.reshape(-1, 1, 2)\n",
    "    \n",
    "    # Update old_gray for next optical flow calculation\n",
    "    old_gray = gray.copy()\n",
    "    \n",
    "    # Draw tracking history\n",
    "    for i in range(1, len(bbox_history)):\n",
    "        prev_x, prev_y = bbox_history[i-1][0] + bbox_history[i-1][2]//2, bbox_history[i-1][1] + bbox_history[i-1][3]//2\n",
    "        curr_x, curr_y = bbox_history[i][0] + bbox_history[i][2]//2, bbox_history[i][1] + bbox_history[i][3]//2\n",
    "        cv2.line(frame_display, (prev_x, prev_y), (curr_x, curr_y), (255, 0, 0), 1)\n",
    "    \n",
    "    # Show the result\n",
    "    cv2.imshow(\"Object Tracking\", frame_display)\n",
    "    \n",
    "    # Break on ESC key\n",
    "    if cv2.waitKey(1) == 27:  # ESC key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VISION",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
