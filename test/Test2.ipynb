{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import deque\n",
    "import math\n",
    "\n",
    "# Tracking parameters\n",
    "TRACKERS = {\n",
    "    \"CSRT\": cv2.legacy.TrackerCSRT_create,\n",
    "    \"KCF\": cv2.legacy.TrackerKCF_create,\n",
    "    \"MOSSE\": cv2.legacy.TrackerMOSSE_create,\n",
    "    \"MIL\": cv2.legacy.TrackerMIL_create\n",
    "}\n",
    "\n",
    "feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Configuration\n",
    "MAX_TRAJECTORY_POINTS = 30\n",
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "MOTION_PREDICTION_ENABLED = True\n",
    "RECOVERY_MAX_ATTEMPTS = 3\n",
    "TRACKER_TYPE = \"CSRT\"  # Change this to use different trackers\n",
    "\n",
    "# Visualization settings\n",
    "SHOW_TRAJECTORY = True\n",
    "SHOW_PREDICTION = True\n",
    "SHOW_FLOW_POINTS = True\n",
    "SHOW_DIRECTION = True\n",
    "SHOW_SPEED = True\n",
    "\n",
    "COLORS = {\n",
    "    'trajectory': (0, 0, 255),\n",
    "    'prediction': (255, 0, 0),\n",
    "    'direction': (0, 255, 255),\n",
    "    'flow_points': (0, 0, 255),\n",
    "    'bbox_good': (0, 255, 0),\n",
    "    'bbox_poor': (0, 0, 255)\n",
    "}\n",
    "\n",
    "def recover_tracking(frame, last_bbox):\n",
    "    \"\"\"Attempt to recover lost tracking using mean shift\"\"\"\n",
    "    try:\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        x, y, w, h = map(int, last_bbox)\n",
    "        \n",
    "        # Validate dimensions\n",
    "        h_frame, w_frame = frame.shape[:2]\n",
    "        x = max(0, min(x, w_frame - 2))\n",
    "        y = max(0, min(y, h_frame - 2))\n",
    "        w = max(1, min(w, w_frame - x))\n",
    "        h = max(1, min(h, h - y))\n",
    "        \n",
    "        roi_hsv = hsv[y:y+h, x:x+w]\n",
    "        roi_hist = cv2.calcHist([roi_hsv], [0], None, [180], [0, 180])\n",
    "        cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "        \n",
    "        dst = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
    "        term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "        ret, track_window = cv2.meanShift(dst, (x, y, w, h), term_crit)\n",
    "        \n",
    "        return track_window if ret == 0 else last_bbox\n",
    "    except:\n",
    "        return last_bbox\n",
    "\n",
    "def calculate_confidence(good_new, good_old):\n",
    "    \"\"\"Calculate tracking confidence based on optical flow\"\"\"\n",
    "    if len(good_new) < 5:\n",
    "        return 0.0\n",
    "    \n",
    "    flow_distances = np.linalg.norm(good_new - good_old, axis=1)\n",
    "    consistency = 1.0 - (np.std(flow_distances) / (np.mean(flow_distances) + 1e-6))\n",
    "    return max(0.0, min(1.0, consistency))\n",
    "\n",
    "def calculate_speed(trajectory_points, fps):\n",
    "    \"\"\"Calculate speed in pixels per second\"\"\"\n",
    "    if len(trajectory_points) < 2:\n",
    "        return 0.0\n",
    "    \n",
    "    p1, p2 = trajectory_points[-2], trajectory_points[-1]\n",
    "    distance = math.sqrt((p2[0] - p1[0])**2 + (p2[1] - p1[1])**2)\n",
    "    return distance * (fps or 1.0)\n",
    "\n",
    "def predict_next_position(trajectory_points):\n",
    "    \"\"\"Predict next position using velocity vector\"\"\"\n",
    "    if len(trajectory_points) < 2:\n",
    "        return None\n",
    "    \n",
    "    p1, p2 = trajectory_points[-2], trajectory_points[-1]\n",
    "    velocity = (p2[0] - p1[0], p2[1] - p1[1])\n",
    "    return (int(p2[0] + velocity[0]), int(p2[1] + velocity[1]))\n",
    "\n",
    "def main(video_source=0):\n",
    "    cap = cv2.VideoCapture(video_source)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error opening video source\")\n",
    "        return\n",
    "\n",
    "    # Initial frame and ROI selection\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error reading initial frame\")\n",
    "        return\n",
    "\n",
    "    bbox = cv2.selectROI(\"Select Object\", frame, False)\n",
    "    cv2.destroyWindow(\"Select Object\")\n",
    "    x, y, w, h = map(int, bbox)\n",
    "\n",
    "    # Initialize tracker and optical flow\n",
    "    tracker = TRACKERS[TRACKER_TYPE]()\n",
    "    tracker.init(frame, bbox)\n",
    "    prev_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    roi = prev_frame[y:y+h, x:x+w]\n",
    "    prev_pts = cv2.goodFeaturesToTrack(roi, mask=None, **feature_params)\n",
    "    if prev_pts is not None:\n",
    "        prev_pts += np.array([x, y], dtype=np.float32)\n",
    "\n",
    "    trajectory = deque(maxlen=MAX_TRAJECTORY_POINTS)\n",
    "    paused = False\n",
    "    confidence = 1.0\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    while True:\n",
    "        if not paused:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            # Tracking update\n",
    "            success, bbox = tracker.update(frame)\n",
    "            x, y, w, h = map(int, bbox)\n",
    "            center = (int(x + w/2), int(y + h/2))\n",
    "            trajectory.append(center)\n",
    "\n",
    "            # Optical flow calculation\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            if prev_pts is not None and len(prev_pts) > 5:\n",
    "                next_pts, status, _ = cv2.calcOpticalFlowPyrLK(prev_frame, gray, prev_pts, None, **lk_params)\n",
    "                \n",
    "                if next_pts is not None:\n",
    "                    good_new = next_pts[status == 1]\n",
    "                    good_old = prev_pts[status == 1]\n",
    "                    confidence = calculate_confidence(good_new, good_old)\n",
    "                    \n",
    "                    if confidence > CONFIDENCE_THRESHOLD:\n",
    "                        movement = np.mean(good_new - good_old, axis=0)\n",
    "                        bbox = (x + movement[0], y + movement[1], w, h)\n",
    "                        prev_pts = good_new.reshape(-1, 1, 2)\n",
    "            \n",
    "            prev_frame = gray.copy()\n",
    "\n",
    "            # Visualization\n",
    "            color = COLORS['bbox_good'] if confidence > CONFIDENCE_THRESHOLD else COLORS['bbox_poor']\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "\n",
    "            if SHOW_TRAJECTORY and len(trajectory) > 1:\n",
    "                for i in range(1, len(trajectory)):\n",
    "                    alpha = i/len(trajectory)\n",
    "                    cv2.line(frame, trajectory[i-1], trajectory[i], \n",
    "                            tuple(int(c*alpha) for c in COLORS['trajectory']), 2)\n",
    "\n",
    "            if SHOW_PREDICTION and MOTION_PREDICTION_ENABLED:\n",
    "                pred = predict_next_position(trajectory)\n",
    "                if pred:\n",
    "                    cv2.circle(frame, pred, 5, COLORS['prediction'], -1)\n",
    "\n",
    "            if SHOW_DIRECTION and len(trajectory) >= 2:\n",
    "                p1, p2 = trajectory[-2], trajectory[-1]\n",
    "                angle = math.atan2(p2[1]-p1[1], p2[0]-p1[0])\n",
    "                end = (int(x + 50*math.cos(angle)), int(y + 50*math.sin(angle)))\n",
    "                cv2.arrowedLine(frame, (x, y), end, COLORS['direction'], 2)\n",
    "\n",
    "            # Display info\n",
    "            speed = calculate_speed(trajectory, fps)\n",
    "            info = [\n",
    "                f\"Confidence: {confidence:.2f}\",\n",
    "                f\"Speed: {speed:.1f} px/s\",\n",
    "                f\"Position: ({x}, {y})\"\n",
    "            ]\n",
    "            \n",
    "            for i, text in enumerate(info):\n",
    "                cv2.putText(frame, text, (10, 30 + i*30),\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow(\"Tracking\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "        elif key == ord('p'):\n",
    "            paused = not paused\n",
    "        elif key == ord('r'):\n",
    "            tracker = TRACKERS[TRACKER_TYPE]()\n",
    "            tracker.init(frame, bbox)\n",
    "            confidence = 1.0\n",
    "        elif key == ord('c'):\n",
    "            trajectory.clear()\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Use 0 for webcam or file path for video\n",
    "    main(video_source=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted next position: (304, 287)\n",
      "Predicted next position: (308, 287)\n",
      "Predicted next position: (311, 279)\n",
      "Predicted next position: (346, 279)\n",
      "Predicted next position: (409, 299)\n",
      "Predicted next position: (508, 288)\n",
      "Predicted next position: (528, 287)\n",
      "Predicted next position: (517, 280)\n",
      "Predicted next position: (516, 278)\n",
      "Predicted next position: (392, 259)\n",
      "Predicted next position: (326, 266)\n",
      "Predicted next position: (232, 284)\n",
      "Predicted next position: (298, 288)\n",
      "Predicted next position: (324, 280)\n",
      "Predicted next position: (364, 291)\n",
      "Predicted next position: (329, 292)\n",
      "Predicted next position: (284, 297)\n",
      "Predicted next position: (305, 289)\n",
      "Predicted next position: (369, 113)\n",
      "Predicted next position: (320, 388)\n",
      "Predicted next position: (317, 287)\n",
      "Predicted next position: (303, 307)\n",
      "Predicted next position: (267, 301)\n",
      "Predicted next position: (274, 298)\n",
      "Predicted next position: (264, 303)\n",
      "Predicted next position: (255, 309)\n",
      "Predicted next position: (246, 301)\n",
      "Predicted next position: (233, 301)\n",
      "Predicted next position: (282, 284)\n",
      "Predicted next position: (301, 293)\n",
      "Predicted next position: (376, 267)\n",
      "Predicted next position: (377, 284)\n",
      "Predicted next position: (359, 280)\n",
      "Predicted next position: (342, 277)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import deque\n",
    "import time\n",
    "\n",
    "# Tracking parameters\n",
    "TRACKERS = {\n",
    "    \"CSRT\": cv2.legacy.TrackerCSRT_create,\n",
    "    \"KCF\": cv2.legacy.TrackerKCF_create,\n",
    "    \"MOSSE\": cv2.legacy.TrackerMOSSE_create,\n",
    "    \"MIL\": cv2.legacy.TrackerMIL_create\n",
    "}\n",
    "\n",
    "# Optical Flow parameters\n",
    "feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "class ObjectTracker:\n",
    "    def __init__(self, tracker_type='CSRT', max_trajectory=30, confidence_threshold=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the object tracker\n",
    "        \n",
    "        :param tracker_type: Tracking algorithm to use\n",
    "        :param max_trajectory: Maximum number of trajectory points to store\n",
    "        :param confidence_threshold: Minimum confidence to maintain tracking\n",
    "        \"\"\"\n",
    "        self.tracker_type = tracker_type\n",
    "        self.tracker = TRACKERS[tracker_type]()\n",
    "        self.max_trajectory = max_trajectory\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        \n",
    "        # Tracking variables\n",
    "        self.trajectory_points = deque(maxlen=max_trajectory)\n",
    "        self.prev_frame = None\n",
    "        self.prev_pts = None\n",
    "        self.confidence_score = 1.0\n",
    "        self.speed = 0.0\n",
    "        \n",
    "    def initialize_tracker(self, frame, bbox):\n",
    "        \"\"\"\n",
    "        Initialize tracker with initial bounding box\n",
    "        \n",
    "        :param frame: First video frame\n",
    "        :param bbox: Initial bounding box (x, y, width, height)\n",
    "        \"\"\"\n",
    "        # Validate and adjust bbox\n",
    "        bbox = self._validate_bbox(bbox, frame.shape)\n",
    "        x, y, w, h = map(int, bbox)\n",
    "        \n",
    "        # Convert frame to grayscale\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Initialize tracker\n",
    "        self.tracker = TRACKERS[self.tracker_type]()\n",
    "        self.tracker.init(frame, bbox)\n",
    "        \n",
    "        # Initialize optical flow points\n",
    "        roi = gray_frame[y:y+h, x:x+w]\n",
    "        self.prev_pts = cv2.goodFeaturesToTrack(roi, mask=None, **feature_params)\n",
    "        if self.prev_pts is not None:\n",
    "            self.prev_pts += np.array([x, y], dtype=np.float32)\n",
    "        \n",
    "        self.prev_frame = gray_frame\n",
    "        \n",
    "    def track(self, frame, fps=30):\n",
    "        \"\"\"\n",
    "        Track object in the current frame\n",
    "        \n",
    "        :param frame: Current video frame\n",
    "        :param fps: Frames per second for speed calculation\n",
    "        :return: Tracking results (success, new bbox, processed frame)\n",
    "        \"\"\"\n",
    "        # Convert frame to grayscale\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        try:\n",
    "            # Update tracker\n",
    "            success, new_bbox = self.tracker.update(frame)\n",
    "            \n",
    "            if not success:\n",
    "                # Attempt recovery\n",
    "                new_bbox = self._recover_tracking(frame, new_bbox)\n",
    "                success = True\n",
    "                self.confidence_score *= 0.5\n",
    "            \n",
    "            # Validate bbox\n",
    "            new_bbox = self._validate_bbox(new_bbox, frame.shape)\n",
    "            x, y, w, h = map(int, new_bbox)\n",
    "            \n",
    "            # Calculate center point and update trajectory\n",
    "            center_point = (int(x + w/2), int(y + h/2))\n",
    "            self.trajectory_points.append(center_point)\n",
    "            \n",
    "            # Calculate speed\n",
    "            if len(self.trajectory_points) >= 2:\n",
    "                self.speed = self._calculate_speed(fps)\n",
    "            \n",
    "            # Optical flow analysis\n",
    "            if self.prev_frame is not None and self.prev_pts is not None and len(self.prev_pts) > 5:\n",
    "                next_pts, status, _ = cv2.calcOpticalFlowPyrLK(\n",
    "                    self.prev_frame, gray_frame, self.prev_pts, None, **lk_params\n",
    "                )\n",
    "                \n",
    "                if next_pts is not None:\n",
    "                    good_new = next_pts[status == 1]\n",
    "                    good_old = self.prev_pts[status == 1]\n",
    "                    \n",
    "                    # Calculate confidence\n",
    "                    self.confidence_score = self._calculate_confidence(good_new, good_old)\n",
    "                    \n",
    "                    # Update tracking if confidence is good\n",
    "                    if len(good_new) > 5 and self.confidence_score > self.confidence_threshold:\n",
    "                        movement = np.mean(good_new - good_old, axis=0)\n",
    "                        new_x, new_y = x + movement[0], y + movement[1]\n",
    "                        new_bbox = (new_x, new_y, w, h)\n",
    "                        \n",
    "                        self.prev_pts = good_new.reshape(-1, 1, 2)\n",
    "                        self.prev_frame = gray_frame.copy()\n",
    "            \n",
    "            # Annotate frame with tracking information\n",
    "            annotated_frame = frame.copy()\n",
    "            cv2.rectangle(annotated_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            \n",
    "            return success, new_bbox, annotated_frame\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Tracking error: {e}\")\n",
    "            return False, None, frame\n",
    "    \n",
    "    def _validate_bbox(self, bbox, frame_shape):\n",
    "        \"\"\"\n",
    "        Validate and adjust bbox to be within frame bounds\n",
    "        \n",
    "        :param bbox: Bounding box coordinates\n",
    "        :param frame_shape: Shape of the frame\n",
    "        :return: Adjusted bbox\n",
    "        \"\"\"\n",
    "        x, y, w, h = map(int, bbox)\n",
    "        h_frame, w_frame = frame_shape[:2]\n",
    "        \n",
    "        x = max(0, min(x, w_frame - 2))\n",
    "        y = max(0, min(y, h_frame - 2))\n",
    "        w = max(1, min(w, w_frame - x))\n",
    "        h = max(1, min(h, h_frame - y))\n",
    "        \n",
    "        return (x, y, w, h)\n",
    "    \n",
    "    def _recover_tracking(self, frame, last_bbox):\n",
    "        \"\"\"\n",
    "        Attempt to recover lost tracking\n",
    "        \n",
    "        :param frame: Current video frame\n",
    "        :param last_bbox: Last known bounding box\n",
    "        :return: Recovered bbox\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Convert to HSV for better color-based detection\n",
    "            hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "            x, y, w, h = map(int, last_bbox)\n",
    "            \n",
    "            # Ensure bbox dimensions are positive and within frame bounds\n",
    "            h_frame, w_frame = frame.shape[:2]\n",
    "            x = max(0, min(x, w_frame - 2))\n",
    "            y = max(0, min(y, h_frame - 2))\n",
    "            w = max(1, min(w, w_frame - x))\n",
    "            h = max(1, min(h, h_frame - y))\n",
    "            \n",
    "            roi_hsv = hsv[y:y+h, x:x+w]\n",
    "            \n",
    "            # Calculate histogram of the ROI\n",
    "            roi_hist = cv2.calcHist([roi_hsv], [0], None, [180], [0, 180])\n",
    "            cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "            \n",
    "            # Apply back projection\n",
    "            dst = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
    "            \n",
    "            # Apply meanshift to get the new location\n",
    "            term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "            ret, track_window = cv2.meanShift(dst, (x, y, w, h), term_crit)\n",
    "            \n",
    "            return track_window if ret != 0 else last_bbox\n",
    "        except Exception as e:\n",
    "            print(f\"Recovery failed: {e}\")\n",
    "            return last_bbox\n",
    "    \n",
    "    def _calculate_confidence(self, good_new, good_old):\n",
    "        \"\"\"\n",
    "        Calculate tracking confidence based on optical flow consistency\n",
    "        \n",
    "        :param good_new: New feature points\n",
    "        :param good_old: Old feature points\n",
    "        :return: Confidence score\n",
    "        \"\"\"\n",
    "        if len(good_new) < 5:\n",
    "            return 0.0\n",
    "        \n",
    "        flow_distances = np.linalg.norm(good_new - good_old, axis=1)\n",
    "        consistency = 1.0 - (np.std(flow_distances) / (np.mean(flow_distances) + 1e-6))\n",
    "        return max(0.0, min(1.0, consistency))\n",
    "    \n",
    "    def _calculate_speed(self, fps):\n",
    "        \"\"\"\n",
    "        Calculate object speed in pixels per second\n",
    "        \n",
    "        :param fps: Frames per second\n",
    "        :return: Speed in pixels per second\n",
    "        \"\"\"\n",
    "        if len(self.trajectory_points) < 2:\n",
    "            return 0.0\n",
    "        \n",
    "        # Calculate distance between last two points\n",
    "        p1, p2 = self.trajectory_points[-2], self.trajectory_points[-1]\n",
    "        distance = math.sqrt((p2[0] - p1[0])**2 + (p2[1] - p1[1])**2)\n",
    "        \n",
    "        # Convert to pixels per second\n",
    "        return distance * (fps or 1.0)\n",
    "    \n",
    "    def predict_next_position(self):\n",
    "        \"\"\"\n",
    "        Predict next position based on recent motion\n",
    "        \n",
    "        :return: Predicted next position or None\n",
    "        \"\"\"\n",
    "        if len(self.trajectory_points) < 2:\n",
    "            return None\n",
    "        \n",
    "        # Calculate velocity vector from last two points\n",
    "        p1, p2 = self.trajectory_points[-2], self.trajectory_points[-1]\n",
    "        velocity = (p2[0] - p1[0], p2[1] - p1[1])\n",
    "        \n",
    "        # Predict next position\n",
    "        predicted = (int(p2[0] + velocity[0]), int(p2[1] + velocity[1]))\n",
    "        return predicted\n",
    "\n",
    "def main():\n",
    "    # Example usage\n",
    "    cap = cv2.VideoCapture(0)  # Use 0 for webcam or provide video file path\n",
    "    \n",
    "    # Wait for the first frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to capture first frame\")\n",
    "        return\n",
    "    \n",
    "    # Select initial bounding box\n",
    "    bbox = cv2.selectROI(\"Select Object\", frame, fromCenter=False, showCrosshair=True)\n",
    "    cv2.destroyWindow(\"Select Object\")\n",
    "    \n",
    "    # Initialize tracker\n",
    "    tracker = ObjectTracker(tracker_type='CSRT')\n",
    "    tracker.initialize_tracker(frame, bbox)\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Track object\n",
    "        success, new_bbox, annotated_frame = tracker.track(frame)\n",
    "        \n",
    "        if success and new_bbox is not None:\n",
    "            # Optional: add visualization or logging here\n",
    "            cv2.imshow(\"Tracking\", annotated_frame)\n",
    "        \n",
    "        # Optional: predict next position\n",
    "        predicted_pos = tracker.predict_next_position()\n",
    "        if predicted_pos:\n",
    "            print(f\"Predicted next position: {predicted_pos}\")\n",
    "        \n",
    "        # Exit on 'q' key press\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import math\n",
    "\n",
    "# Core tracking parameters\n",
    "TRACKERS = {\n",
    "    \"CSRT\": cv2.legacy.TrackerCSRT_create,\n",
    "    \"KCF\": cv2.legacy.TrackerKCF_create,\n",
    "    \"MOSSE\": cv2.legacy.TrackerMOSSE_create,\n",
    "    \"MIL\": cv2.legacy.TrackerMIL_create\n",
    "}\n",
    "\n",
    "# Optical flow parameters\n",
    "feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=2, \n",
    "                criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame = cap.read()\n",
    "if not ret:\n",
    "    print(\"Failed to open camera\")\n",
    "    exit()\n",
    "\n",
    "# Select ROI and initialize tracker\n",
    "bbox = cv2.selectROI(\"Select Object\", frame, fromCenter=False)\n",
    "cv2.destroyWindow(\"Select Object\")\n",
    "\n",
    "tracker = TRACKERS[\"CSRT\"]()\n",
    "tracker.init(frame, bbox)\n",
    "\n",
    "# Initialize tracking variables\n",
    "prev_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "x, y, w, h = map(int, bbox)\n",
    "roi = prev_frame[y:y+h, x:x+w]\n",
    "prev_pts = cv2.goodFeaturesToTrack(roi, mask=None, **feature_params)\n",
    "if prev_pts is not None:\n",
    "    prev_pts += np.array([x, y], dtype=np.float32)\n",
    "\n",
    "trajectory_points = deque(maxlen=30)\n",
    "confidence_score = 1.0\n",
    "\n",
    "# Main tracking loop\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    success, bbox = tracker.update(frame)\n",
    "\n",
    "    if success:\n",
    "        x, y, w, h = map(int, bbox)\n",
    "        center_point = (int(x + w/2), int(y + h/2))\n",
    "        trajectory_points.append(center_point)\n",
    "\n",
    "        # Update optical flow\n",
    "        if prev_pts is not None and len(prev_pts) > 5:\n",
    "            next_pts, status, _ = cv2.calcOpticalFlowPyrLK(\n",
    "                prev_frame, gray_frame, prev_pts, None, **lk_params)\n",
    "            \n",
    "            if next_pts is not None:\n",
    "                good_new = next_pts[status == 1]\n",
    "                good_old = prev_pts[status == 1]\n",
    "                \n",
    "                # Calculate tracking confidence\n",
    "                if len(good_new) > 5:\n",
    "                    flow_distances = np.linalg.norm(good_new - good_old, axis=1)\n",
    "                    confidence_score = 1.0 - (np.std(flow_distances) / (np.mean(flow_distances) + 1e-6))\n",
    "                    confidence_score = max(0.0, min(1.0, confidence_score))\n",
    "                    \n",
    "                    if confidence_score > 0.5:\n",
    "                        movement = np.mean(good_new - good_old, axis=0)\n",
    "                        bbox = (x + movement[0], y + movement[1], w, h)\n",
    "                \n",
    "                prev_pts = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "        # Draw tracking visualization\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), \n",
    "                     (0, int(255 * confidence_score), 0), 2)\n",
    "        \n",
    "        # Draw trajectory\n",
    "        if len(trajectory_points) > 1:\n",
    "            for i in range(1, len(trajectory_points)):\n",
    "                cv2.line(frame, trajectory_points[i-1], \n",
    "                        trajectory_points[i], (0, 0, 255), 2)\n",
    "\n",
    "        # Draw optical flow points\n",
    "        if 'good_new' in locals():\n",
    "            for pt in good_new:\n",
    "                cv2.circle(frame, tuple(map(int, pt)), 3, (0, 0, 255), -1)\n",
    "\n",
    "    prev_frame = gray_frame.copy()\n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 142\u001b[0m\n\u001b[0;32m    139\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 142\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 121\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m success, bbox, trajectory \u001b[38;5;241m=\u001b[39m \u001b[43mtracker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Draw tracking box\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m success:\n",
      "Cell \u001b[1;32mIn[1], line 73\u001b[0m, in \u001b[0;36mObjectTracker.update\u001b[1;34m(self, frame)\u001b[0m\n\u001b[0;32m     71\u001b[0m     bbox \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecover_tracking(frame, bbox)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mTRACKERS[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracker_type]()\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtracker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfidence_score \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Update trajectory\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4208: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "tracker = None\n",
    "bbox = None\n",
    "tracking = False\n",
    "\n",
    "# Optical flow parameters\n",
    "feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Tracking variables\n",
    "prev_frame = None\n",
    "prev_pts = None\n",
    "tracking_history = []  # Store recent tracking positions\n",
    "\n",
    "# Select ROI\n",
    "ret, frame = cap.read()\n",
    "if not ret or frame is None:\n",
    "    print('Error: Unable to capture video')\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    cv2.putText(frame, \"Select ROI & press ENTER\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "    bbox = cv2.selectROI(\"Select ROI\", frame, fromCenter=False, showCrosshair=True)\n",
    "    cv2.destroyWindow(\"Select ROI\")\n",
    "\n",
    "    if bbox != (0, 0, 0, 0):\n",
    "        # Initialize CSRT tracker\n",
    "        tracker = cv2.TrackerCSRT_create()\n",
    "        tracker.init(frame, bbox)\n",
    "        tracking = True\n",
    "        \n",
    "        # Initialize optical flow\n",
    "        prev_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        x, y, w, h = map(int, bbox)\n",
    "        roi = prev_frame[y:y+h, x:x+w]\n",
    "        prev_pts = cv2.goodFeaturesToTrack(roi, mask=None, **feature_params)\n",
    "        if prev_pts is not None:\n",
    "            prev_pts = prev_pts + np.array([x, y], dtype=np.float32)  # Adjust coordinates to global frame\n",
    "\n",
    "def update_tracker_with_optical_flow(frame, gray_frame):\n",
    "    global prev_frame, prev_pts, bbox\n",
    "    \n",
    "    if prev_frame is None or prev_pts is None or len(prev_pts) < 5:\n",
    "        return False, bbox\n",
    "    \n",
    "    # Calculate optical flow\n",
    "    next_pts, status, _ = cv2.calcOpticalFlowPyrLK(prev_frame, gray_frame, prev_pts, None, **lk_params)\n",
    "    \n",
    "    # Filter good points\n",
    "    if next_pts is not None:\n",
    "        good_new = next_pts[status == 1]\n",
    "        good_old = prev_pts[status == 1]\n",
    "        \n",
    "        if len(good_new) > 5:  # Enough points to estimate movement\n",
    "            # Calculate bounding box movement\n",
    "            movement = np.mean(good_new - good_old, axis=0)\n",
    "            x, y, w, h = bbox\n",
    "            \n",
    "            # Update bounding box position\n",
    "            new_x = x + movement[0]\n",
    "            new_y = y + movement[1]\n",
    "            \n",
    "            # Update previous points for next iteration\n",
    "            prev_pts = good_new.reshape(-1, 1, 2)\n",
    "            prev_frame = gray_frame.copy()\n",
    "            \n",
    "            # Update bbox\n",
    "            bbox = (new_x, new_y, w, h)\n",
    "            return True, bbox\n",
    "    \n",
    "    # Not enough points to track\n",
    "    return False, bbox\n",
    "\n",
    "# Main loop\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret or frame is None:\n",
    "        print('Error: Unable to capture video')\n",
    "        break\n",
    "    \n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    if tracking and tracker:\n",
    "        # 1. Try CSRT tracker\n",
    "        tracking_success, new_bbox = tracker.update(frame)\n",
    "        \n",
    "        # 2. Apply optical flow\n",
    "        of_success, of_bbox = update_tracker_with_optical_flow(frame, gray_frame)\n",
    "            \n",
    "        # Decide which result to use\n",
    "        if tracking_success and of_success:\n",
    "            # Blend CSRT and optical flow results (weighted average)\n",
    "            csrt_weight = 0.7\n",
    "            of_weight = 0.3\n",
    "            x1, y1, w1, h1 = new_bbox\n",
    "            x2, y2, w2, h2 = of_bbox\n",
    "            \n",
    "            blended_x = x1 * csrt_weight + x2 * of_weight\n",
    "            blended_y = y1 * csrt_weight + y2 * of_weight\n",
    "            bbox = (blended_x, blended_y, w1, h1)  # Keep original width/height\n",
    "            \n",
    "            # Update optical flow points occasionally for long-term stability\n",
    "            if len(tracking_history) % 10 == 0:\n",
    "                x, y, w, h = map(int, bbox)\n",
    "                roi = gray_frame[max(0, y):min(frame.shape[0], y+h), max(0, x):min(frame.shape[1], x+w)]\n",
    "                if roi.size > 0:\n",
    "                    pts = cv2.goodFeaturesToTrack(roi, mask=None, **feature_params)\n",
    "                    if pts is not None and pts.size > 0:\n",
    "                        prev_pts = pts + np.array([x, y], dtype=np.float32)\n",
    "                        prev_frame = gray_frame.copy()\n",
    "        elif tracking_success:\n",
    "            bbox = new_bbox\n",
    "        elif of_success:\n",
    "            bbox = of_bbox\n",
    "        \n",
    "        # Store tracking history\n",
    "        if tracking_success or of_success:\n",
    "            x, y, w, h = map(float, bbox)\n",
    "            center_x, center_y = x + w/2, y + h/2\n",
    "            tracking_history.append((center_x, center_y))\n",
    "            if len(tracking_history) > 30:  # Keep last 30 positions\n",
    "                tracking_history.pop(0)\n",
    "            \n",
    "            print(\"Tracking: Success\")\n",
    "        else:\n",
    "            print(\"Tracking: Lost\")\n",
    "        \n",
    "    # Draw tracking information on frame\n",
    "    if bbox is not None:\n",
    "        x, y, w, h = map(int, bbox)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw tracking history\n",
    "        if len(tracking_history) > 1:\n",
    "            for i in range(1, len(tracking_history)):\n",
    "                pt1 = tuple(map(int, tracking_history[i-1]))\n",
    "                pt2 = tuple(map(int, tracking_history[i]))\n",
    "                cv2.line(frame, pt1, pt2, (0, 0, 255), 1)\n",
    "    \n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    "    \n",
    "    # Exit on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Clean up\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "tracker = None\n",
    "bbox = None\n",
    "tracking = False\n",
    "\n",
    "# Optical flow parameters\n",
    "feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Kalman Filter setup\n",
    "kalman = cv2.KalmanFilter(4, 2)  # 4 state variables (x, y, vx, vy), 2 measurement variables (x, y)\n",
    "kalman.transitionMatrix = np.array([[1, 0, 1, 0],  [0, 1, 0, 1],  [0, 0, 1, 0],  [0, 0, 0, 1]], np.float32)\n",
    "kalman.measurementMatrix = np.array([[1, 0, 0, 0],  [0, 1, 0, 0]], np.float32)\n",
    "kalman.processNoiseCov = np.eye(4, dtype=np.float32) * 0.03\n",
    "kalman.measurementNoiseCov = np.eye(2, dtype=np.float32) * 0.3\n",
    "kalman.statePre = np.zeros((4, 1), np.float32)\n",
    "kalman.statePost = np.zeros((4, 1), np.float32)\n",
    "\n",
    "# Tracking variables\n",
    "prev_frame = None\n",
    "prev_pts = None\n",
    "\n",
    "# Select ROI\n",
    "ret, frame = cap.read()\n",
    "if not ret or frame is None:\n",
    "    print('Error: Unable to capture video')\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    cv2.putText(frame, \"Select ROI & press ENTER\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "    bbox = cv2.selectROI(\"Select ROI\", frame, fromCenter=False, showCrosshair=True)\n",
    "    cv2.destroyWindow(\"Select ROI\")\n",
    "\n",
    "    if bbox != (0, 0, 0, 0):\n",
    "        tracker = cv2.TrackerCSRT_create()\n",
    "        tracker.init(frame, bbox)\n",
    "        tracking = True\n",
    "        prev_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        x, y, w, h = map(int, bbox)\n",
    "        roi = prev_frame[y:y+h, x:x+w]\n",
    "        prev_pts = cv2.goodFeaturesToTrack(roi, mask=None, **feature_params)\n",
    "        if prev_pts is not None:\n",
    "            prev_pts = prev_pts + np.array([x, y], dtype=np.float32)\n",
    "    \n",
    "    # Initialize Kalman Filter\n",
    "    kalman.statePre[:2] = np.array([[x + w / 2], [y + h / 2]], np.float32)\n",
    "    kalman.statePost = kalman.statePre.copy()\n",
    "\n",
    "def update_tracker_with_optical_flow(frame, gray_frame):\n",
    "    global prev_frame, prev_pts, bbox\n",
    "    if prev_frame is None or prev_pts is None or len(prev_pts) < 5:\n",
    "        return False, bbox\n",
    "    \n",
    "    next_pts, status, _ = cv2.calcOpticalFlowPyrLK(prev_frame, gray_frame, prev_pts, None, **lk_params)\n",
    "    if next_pts is not None:\n",
    "        good_new = next_pts[status == 1]\n",
    "        good_old = prev_pts[status == 1]\n",
    "        if len(good_new) > 5:\n",
    "            movement = np.mean(good_new - good_old, axis=0)\n",
    "            x, y, w, h = bbox\n",
    "            new_x = x + movement[0]\n",
    "            new_y = y + movement[1]\n",
    "            prev_pts = good_new.reshape(-1, 1, 2)\n",
    "            prev_frame = gray_frame.copy()\n",
    "            bbox = (new_x, new_y, w, h)\n",
    "            return True, bbox\n",
    "    return False, bbox\n",
    "\n",
    "# Main loop\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret or frame is None:\n",
    "        print('Error: Unable to capture video')\n",
    "        break\n",
    "    \n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    if tracking:\n",
    "        # Predict next position using Kalman Filter\n",
    "        prediction = kalman.predict()\n",
    "        pred_x, pred_y = prediction[0], prediction[1]\n",
    "        \n",
    "        # Update tracker\n",
    "        tracking_success, new_bbox = tracker.update(frame)\n",
    "        of_success, of_bbox = update_tracker_with_optical_flow(frame, gray_frame)\n",
    "        \n",
    "        if tracking_success and of_success:\n",
    "            x1, y1, w1, h1 = new_bbox\n",
    "            x2, y2, w2, h2 = of_bbox\n",
    "            measured_x = (x1 + x2) / 2\n",
    "            measured_y = (y1 + y2) / 2\n",
    "        elif tracking_success:\n",
    "            measured_x, measured_y = new_bbox[0], new_bbox[1]\n",
    "        elif of_success:\n",
    "            measured_x, measured_y = of_bbox[0], of_bbox[1]\n",
    "        else:\n",
    "            measured_x, measured_y = pred_x, pred_y\n",
    "        \n",
    "        measurement = np.array([[np.float32(measured_x)], [np.float32(measured_y)]])\n",
    "        kalman.correct(measurement)\n",
    "        bbox = (measured_x, measured_y, bbox[2], bbox[3])\n",
    "        \n",
    "        x, y, w, h = map(int, bbox)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    \n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " [[327. 403.]]\n",
      "\n",
      " [[298. 416.]]\n",
      "\n",
      " [[312. 420.]]\n",
      "\n",
      " [[290. 413.]]]\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Lost\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "tracker = None\n",
    "bbox = None\n",
    "tracking = False\n",
    "\n",
    "# Optical flow parameters\n",
    "feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=2, criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Tracking variables\n",
    "prev_frame = None\n",
    "prev_pts = None\n",
    "tracking_history = []  # Store recent tracking positions\n",
    "\n",
    "# Select ROI\n",
    "ret, frame = cap.read()\n",
    "cv2.putText(frame, \"Select ROI & press ENTER\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "bbox = cv2.selectROI(\"Select ROI\", frame, fromCenter=False, showCrosshair=True)\n",
    "cv2.destroyWindow(\"Select ROI\")\n",
    "\n",
    "if bbox != (0, 0, 0, 0):\n",
    "    # Initialize CSRT tracker\n",
    "    tracker = cv2.TrackerCSRT_create()\n",
    "    tracker.init(frame, bbox)\n",
    "    tracking = True\n",
    "    \n",
    "    # Initialize optical flow\n",
    "    prev_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    x, y, w, h = map(int, bbox)\n",
    "    roi = prev_frame[y:y+h, x:x+w]\n",
    "    prev_pts = cv2.goodFeaturesToTrack(roi, mask=None, **feature_params)\n",
    "    if prev_pts is not None:\n",
    "        prev_pts = prev_pts + np.array([x, y], dtype=np.float32)  # Adjust coordinates to global frame\n",
    "    print('bbox:', bbox)\n",
    "    print('roi:', roi)\n",
    "    print('prev_pts:', prev_pts)\n",
    "\n",
    "def update_tracker_with_optical_flow(frame, gray_frame):\n",
    "    global prev_frame, prev_pts, bbox\n",
    "    \n",
    "    if prev_frame is None or prev_pts is None or len(prev_pts) < 5:\n",
    "        return False, bbox\n",
    "    \n",
    "    # Calculate optical flow\n",
    "    next_pts, status, _ = cv2.calcOpticalFlowPyrLK(prev_frame, gray_frame, prev_pts, None, **lk_params)\n",
    "    \n",
    "    # Filter good points\n",
    "    if next_pts is not None:\n",
    "        good_new = next_pts[status == 1]\n",
    "        good_old = prev_pts[status == 1]\n",
    "        \n",
    "        if len(good_new) > 5:  # Enough points to estimate movement\n",
    "            # Calculate bounding box movement\n",
    "            movement = np.mean(good_new - good_old, axis=0)\n",
    "            x, y, w, h = bbox\n",
    "            \n",
    "            # Update bounding box position\n",
    "            new_x = x + movement[0]\n",
    "            new_y = y + movement[1]\n",
    "            \n",
    "            # Update previous points for next iteration\n",
    "            prev_pts = good_new.reshape(-1, 1, 2)\n",
    "            prev_frame = gray_frame.copy()\n",
    "            \n",
    "            # Update bbox\n",
    "            bbox = (new_x, new_y, w, h)\n",
    "            return True, bbox\n",
    "    \n",
    "    # Not enough points to track\n",
    "    return False, bbox\n",
    "\n",
    "# Main loop\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    if tracking and tracker:\n",
    "        # 1. Try CSRT tracker\n",
    "        tracking_success, new_bbox = tracker.update(frame)\n",
    "        \n",
    "        # 2. Apply optical flow\n",
    "        of_success, of_bbox = update_tracker_with_optical_flow(frame, gray_frame)\n",
    "            \n",
    "        # Decide which result to use\n",
    "        if tracking_success and of_success:\n",
    "            # Blend CSRT and optical flow results (weighted average)\n",
    "            csrt_weight = 0.7\n",
    "            of_weight = 0.3\n",
    "            x1, y1, w1, h1 = new_bbox\n",
    "            x2, y2, w2, h2 = of_bbox\n",
    "            \n",
    "            blended_x = x1 * csrt_weight + x2 * of_weight\n",
    "            blended_y = y1 * csrt_weight + y2 * of_weight\n",
    "            bbox = (blended_x, blended_y, w1, h1)  # Keep original width/height\n",
    "            \n",
    "            # Update optical flow points occasionally for long-term stability\n",
    "            if len(tracking_history) % 10 == 0:\n",
    "                x, y, w, h = map(int, bbox)\n",
    "                roi = gray_frame[max(0, y):min(frame.shape[0], y+h), max(0, x):min(frame.shape[1], x+w)]\n",
    "                if roi.size > 0:\n",
    "                    pts = cv2.goodFeaturesToTrack(roi, mask=None, **feature_params)\n",
    "                    if pts is not None and pts.size > 0:\n",
    "                        prev_pts = pts + np.array([x, y], dtype=np.float32)\n",
    "                        prev_frame = gray_frame.copy()\n",
    "        elif tracking_success:\n",
    "            bbox = new_bbox\n",
    "        elif of_success:\n",
    "            bbox = of_bbox\n",
    "        \n",
    "        # Store tracking history\n",
    "        if tracking_success or of_success:\n",
    "            x, y, w, h = map(float, bbox)\n",
    "            center_x, center_y = x + w/2, y + h/2\n",
    "            tracking_history.append((center_x, center_y))\n",
    "            if len(tracking_history) > 30:  # Keep last 30 positions\n",
    "                tracking_history.pop(0)\n",
    "            \n",
    "            print(\"Tracking: Success\")\n",
    "        else:\n",
    "            print(\"Tracking: Lost\")\n",
    "        \n",
    "    # Draw tracking information on frame\n",
    "    if bbox is not None:\n",
    "        x, y, w, h = map(int, bbox)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw tracking history\n",
    "        if len(tracking_history) > 1:\n",
    "            for i in range(1, len(tracking_history)):\n",
    "                pt1 = tuple(map(int, tracking_history[i-1]))\n",
    "                pt2 = tuple(map(int, tracking_history[i]))\n",
    "                cv2.line(frame, pt1, pt2, (0, 0, 255), 1)\n",
    "    \n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    "    \n",
    "    # Exit on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Clean up\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n",
      "Tracking: Success\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize tracking variables\n",
    "tracker = None\n",
    "bbox = None\n",
    "tracking = False\n",
    "\n",
    "# Optical flow parameters\n",
    "feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=2, \n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Tracking variables\n",
    "prev_frame = None\n",
    "prev_pts = None\n",
    "tracking_history = []  # Store recent tracking positions\n",
    "\n",
    "# Kalman Filter setup\n",
    "kalman = cv2.KalmanFilter(4, 2)  # 4 state variables (x, y, dx, dy), 2 measurement variables (x, y)\n",
    "kalman.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)  # Measurement matrix\n",
    "kalman.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)  # State transition matrix\n",
    "kalman.processNoiseCov = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32) * 0.03  # Process noise\n",
    "kalman.measurementNoiseCov = np.array([[1, 0], [0, 1]], np.float32) * 0.1  # Measurement noise\n",
    "\n",
    "# Select ROI\n",
    "ret, frame = cap.read()\n",
    "cv2.putText(frame, \"Select ROI & press ENTER\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "bbox = cv2.selectROI(\"Select ROI\", frame, fromCenter=False, showCrosshair=True)\n",
    "cv2.destroyWindow(\"Select ROI\")\n",
    "\n",
    "if bbox != (0, 0, 0, 0):\n",
    "    # Initialize CSRT tracker\n",
    "    tracker = cv2.TrackerCSRT_create()\n",
    "    tracker.init(frame, bbox)\n",
    "    tracking = True\n",
    "    \n",
    "    # Initialize optical flow\n",
    "    prev_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    x, y, w, h = map(int, bbox)\n",
    "    roi = prev_frame[y:y+h, x:x+w]\n",
    "    prev_pts = cv2.goodFeaturesToTrack(roi, mask=None, **feature_params)\n",
    "    if prev_pts is not None:\n",
    "        prev_pts = prev_pts + np.array([x, y], dtype=np.float32)  # Adjust coordinates to global frame\n",
    "    \n",
    "    # Initialize Kalman filter with current position\n",
    "    center_x, center_y = x + w/2, y + h/2\n",
    "    kalman.statePre = np.array([[center_x], [center_y], [0], [0]], np.float32)\n",
    "    kalman.statePost = np.array([[center_x], [center_y], [0], [0]], np.float32)\n",
    "\n",
    "def update_tracker_with_optical_flow(frame, gray_frame):\n",
    "    global prev_frame, prev_pts, bbox\n",
    "    \n",
    "    if prev_frame is None or prev_pts is None or len(prev_pts) < 5:\n",
    "        return False, bbox\n",
    "    \n",
    "    # Calculate optical flow\n",
    "    next_pts, status, _ = cv2.calcOpticalFlowPyrLK(prev_frame, gray_frame, prev_pts, None, **lk_params)\n",
    "    \n",
    "    # Filter good points\n",
    "    if next_pts is not None:\n",
    "        good_new = next_pts[status == 1]\n",
    "        good_old = prev_pts[status == 1]\n",
    "        \n",
    "        if len(good_new) > 5:  # Enough points to estimate movement\n",
    "            # Calculate bounding box movement\n",
    "            movement = np.mean(good_new - good_old, axis=0)\n",
    "            x, y, w, h = bbox\n",
    "            \n",
    "            # Update bounding box position\n",
    "            new_x = x + movement[0]\n",
    "            new_y = y + movement[1]\n",
    "            \n",
    "            # Update previous points for next iteration\n",
    "            prev_pts = good_new.reshape(-1, 1, 2)\n",
    "            prev_frame = gray_frame.copy()\n",
    "            \n",
    "            # Update bbox\n",
    "            bbox = (new_x, new_y, w, h)\n",
    "            return True, bbox\n",
    "    \n",
    "    # Not enough points to track\n",
    "    return False, bbox\n",
    "\n",
    "def apply_kalman_filter(bbox):\n",
    "    # Predict\n",
    "    prediction = kalman.predict()\n",
    "    \n",
    "    # Get the current center from bbox\n",
    "    x, y, w, h = bbox\n",
    "    center_x, center_y = x + w/2, y + h/2\n",
    "    \n",
    "    # Correct with measurement\n",
    "    measurement = np.array([[center_x], [center_y]], np.float32)\n",
    "    kalman.correct(measurement)\n",
    "    \n",
    "    # Get the filtered position\n",
    "    filtered_x = kalman.statePost[0][0]\n",
    "    filtered_y = kalman.statePost[1][0]\n",
    "    \n",
    "    # Calculate the new bbox position\n",
    "    new_x = filtered_x - w/2\n",
    "    new_y = filtered_y - h/2\n",
    "    \n",
    "    return (new_x, new_y, w, h)\n",
    "\n",
    "# Main loop\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    if tracking and tracker:\n",
    "        # 1. Try CSRT tracker\n",
    "        tracking_success, new_bbox = tracker.update(frame)\n",
    "        \n",
    "        # 2. Apply optical flow\n",
    "        of_success, of_bbox = update_tracker_with_optical_flow(frame, gray_frame)\n",
    "            \n",
    "        # Decide which result to use\n",
    "        if tracking_success and of_success:\n",
    "            # Blend CSRT and optical flow results (weighted average)\n",
    "            csrt_weight = 0.7\n",
    "            of_weight = 0.3\n",
    "            x1, y1, w1, h1 = new_bbox\n",
    "            x2, y2, w2, h2 = of_bbox\n",
    "            \n",
    "            blended_x = x1 * csrt_weight + x2 * of_weight\n",
    "            blended_y = y1 * csrt_weight + y2 * of_weight\n",
    "            bbox = (blended_x, blended_y, w1, h1)  # Keep original width/height\n",
    "            \n",
    "            # Apply Kalman filter to smooth the result\n",
    "            bbox = apply_kalman_filter(bbox)\n",
    "            \n",
    "            # Update optical flow points occasionally for long-term stability\n",
    "            if len(tracking_history) % 10 == 0:\n",
    "                x, y, w, h = map(int, bbox)\n",
    "                roi = gray_frame[max(0, y):min(frame.shape[0], y+h), \n",
    "                               max(0, x):min(frame.shape[1], x+w)]\n",
    "                if roi.size > 0:\n",
    "                    pts = cv2.goodFeaturesToTrack(roi, mask=None, **feature_params)\n",
    "                    if pts is not None and pts.size > 0:\n",
    "                        prev_pts = pts + np.array([x, y], dtype=np.float32)\n",
    "                        prev_frame = gray_frame.copy()\n",
    "        elif tracking_success:\n",
    "            bbox = new_bbox\n",
    "            # Apply Kalman filter to smooth the result\n",
    "            bbox = apply_kalman_filter(bbox)\n",
    "        elif of_success:\n",
    "            bbox = of_bbox\n",
    "            # Apply Kalman filter to smooth the result\n",
    "            bbox = apply_kalman_filter(bbox)\n",
    "        \n",
    "        # Store tracking history\n",
    "        if tracking_success or of_success:\n",
    "            x, y, w, h = map(float, bbox)\n",
    "            center_x, center_y = x + w/2, y + h/2\n",
    "            tracking_history.append((center_x, center_y))\n",
    "            if len(tracking_history) > 30:  # Keep last 30 positions\n",
    "                tracking_history.pop(0)\n",
    "            \n",
    "            print(\"Tracking: Success\")\n",
    "        else:\n",
    "            print(\"Tracking: Lost\")\n",
    "        \n",
    "    # Draw tracking information on frame\n",
    "    if bbox is not None:\n",
    "        x, y, w, h = map(int, bbox)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "        # Draw tracking history\n",
    "        if len(tracking_history) > 1:\n",
    "            for i in range(1, len(tracking_history)):\n",
    "                pt1 = tuple(map(int, tracking_history[i-1]))\n",
    "                pt2 = tuple(map(int, tracking_history[i]))\n",
    "                cv2.line(frame, pt1, pt2, (0, 0, 255), 1)\n",
    "    \n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    "    \n",
    "    # Exit on 'q' key\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Clean up\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSRT Tracker & Optical Flow & Kalman Filter  & Tracking History\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "tracker = cv2.TrackerCSRT_create()\n",
    "ret, frame = cap.read()\n",
    "bbox = cv2.selectROI(\"Select Object\", frame, False)\n",
    "tracker.init(frame, bbox)\n",
    "\n",
    "prev_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "kalman = cv2.KalmanFilter(4, 2)\n",
    "kalman.measurementMatrix = np.array([[1, 0, 0, 0],[0, 1, 0, 0]], np.float32)\n",
    "kalman.transitionMatrix = np.array([[1, 0, 1, 0],[0, 1, 0, 1],[0, 0, 1, 0],[0, 0, 0, 1]], np.float32)\n",
    "kalman.processNoiseCov = np.eye(4, dtype=np.float32) * 0.03\n",
    "\n",
    "\n",
    "tracking_history = deque(maxlen=10)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    success, bbox = tracker.update(frame)\n",
    "\n",
    "    if success:\n",
    "        x, y, w, h = [int(v) for v in bbox]\n",
    "        center_x, center_y = x + w // 2, y + h // 2\n",
    "\n",
    "        measurement = np.array([[np.float32(center_x)], [np.float32(center_y)]])\n",
    "        kalman.correct(measurement)\n",
    "\n",
    "        tracking_history.append((center_x, center_y, w, h))\n",
    "\n",
    "    else:\n",
    "        \n",
    "        if len(tracking_history) > 1:\n",
    "            # الحصول على آخر موقعين معروفين\n",
    "            p0 = np.array([[tracking_history[-2][:2]]], dtype=np.float32)\n",
    "            p1, st, err = cv2.calcOpticalFlowPyrLK(prev_gray, gray, p0, None)\n",
    "\n",
    "            if p1 is not None and st[0] == 1:\n",
    "                # Optical Flow\n",
    "                pred_x, pred_y = int(p1[0][0][0]), int(p1[0][0][1])\n",
    "            else:\n",
    "                #  Kalman Filter \n",
    "                prediction = kalman.predict()\n",
    "                pred_x, pred_y = int(prediction[0]), int(prediction[1])\n",
    "\n",
    "            # إعادة إنشاء التراكر عند الموقع المتوقع\n",
    "            bbox = (pred_x - w // 2, pred_y - h // 2, w, h)\n",
    "            tracker = cv2.TrackerCSRT_create()\n",
    "            tracker.init(frame, bbox)\n",
    "\n",
    "    prev_gray = gray.copy()\n",
    "\n",
    "    if len(tracking_history) > 0:\n",
    "        last_x, last_y, last_w, last_h = tracking_history[-1]\n",
    "        cv2.rectangle(frame, (last_x - last_w // 2, last_y - last_h // 2),\n",
    "                      (last_x + last_w // 2, last_y + last_h // 2), (0, 255, 0), 2)\n",
    "\n",
    "    for i in range(1, len(tracking_history)):\n",
    "        cv2.line(frame, tracking_history[i - 1][:2], tracking_history[i][:2], (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gemy2\\AppData\\Local\\Temp\\ipykernel_4752\\3232810261.py:76: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  pred_x, pred_y = int(prediction[0]), int(prediction[1])\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "# Initialize webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Read first frame\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Let user select ROI (Region of Interest)\n",
    "bbox = cv2.selectROI(\"Select Object to Track\", frame, False)\n",
    "cv2.destroyWindow(\"Select Object to Track\")\n",
    "\n",
    "# Initialize the CSRT tracker\n",
    "tracker = cv2.legacy.TrackerCSRT_create()\n",
    "tracker.init(frame, bbox)\n",
    "\n",
    "# Initialize variables for tracking\n",
    "tracking_active = True\n",
    "bbox_history = deque(maxlen=10)  # Store last 10 positions\n",
    "bbox_history.append(bbox)\n",
    "\n",
    "# Initialize Kalman filter\n",
    "kalman = cv2.KalmanFilter(4, 2)\n",
    "kalman.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)\n",
    "kalman.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)\n",
    "kalman.processNoiseCov = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32) * 0.03\n",
    "\n",
    "# Initialize variables for optical flow\n",
    "old_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "old_points = None\n",
    "    \n",
    "while True:\n",
    "    # Read a new frame\n",
    "    ret, frame = cap.read()\n",
    "        \n",
    "    # Create a copy of the frame for visualization\n",
    "    frame_display = frame.copy()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 1. CSRT Tracker\n",
    "    if tracking_active:\n",
    "        success, bbox = tracker.update(frame)\n",
    "        \n",
    "        # If tracking is successful, update history and Kalman filter\n",
    "        if success:\n",
    "            x, y, w, h = [int(v) for v in bbox]\n",
    "            bbox_history.append((x, y, w, h))\n",
    "            \n",
    "            # Kalman measurement update\n",
    "            kalman.correct(np.array([[x + w/2], [y + h/2]], np.float32))\n",
    "            \n",
    "            # Save points for optical flow\n",
    "            if old_points is None or len(old_points) < 10:\n",
    "                # Define region for feature detection\n",
    "                roi = old_gray[y:y+h, x:x+w]\n",
    "                # Find good features to track\n",
    "                try:\n",
    "                    points = cv2.goodFeaturesToTrack(roi, 100, 0.01, 10)\n",
    "                    if points is not None:\n",
    "                        old_points = points + np.array([x, y], np.float32)\n",
    "                except cv2.error:\n",
    "                    old_points = None\n",
    "            \n",
    "            # Draw the bbox\n",
    "            cv2.rectangle(frame_display, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame_display, \"Tracking\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        else:\n",
    "            tracking_active = False\n",
    "            \n",
    "    # 2. If tracking fails, use prediction and attempt reinitialization\n",
    "    if not tracking_active:\n",
    "        # Predict using Kalman filter\n",
    "        prediction = kalman.predict()\n",
    "        pred_x, pred_y = int(prediction[0]), int(prediction[1])\n",
    "        \n",
    "        # Use the last known size from history\n",
    "        if bbox_history:\n",
    "            last_x, last_y, last_w, last_h = bbox_history[-1]\n",
    "            predicted_bbox = (pred_x - last_w//2, pred_y - last_h//2, last_w, last_h)\n",
    "            \n",
    "            # Attempt to reinitialize tracker at the predicted position\n",
    "            tracker = cv2.legacy.TrackerCSRT_create()\n",
    "            success = tracker.init(frame, predicted_bbox)\n",
    "            if success:\n",
    "                tracking_active = True\n",
    "                bbox = predicted_bbox\n",
    "            \n",
    "            # Draw the predicted position\n",
    "            cv2.rectangle(frame_display, (pred_x - last_w//2, pred_y - last_h//2), \n",
    "                            (pred_x + last_w//2, pred_y + last_h//2), (0, 0, 255), 2)\n",
    "            cv2.putText(frame_display, \"Predicted\", (pred_x - last_w//2, pred_y - last_h//2 - 10), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    \n",
    "    # 3. Lucas-Kanade Optical Flow for additional tracking\n",
    "    if old_points is not None and len(old_points) > 0:\n",
    "        new_points, status, _ = cv2.calcOpticalFlowPyrLK(old_gray, gray, old_points, None)\n",
    "        \n",
    "        if new_points is not None:\n",
    "            # Keep only good points\n",
    "            good_new = new_points[status == 1]\n",
    "            good_old = old_points[status == 1]\n",
    "            \n",
    "            # If we have enough points, use them to refine the bbox\n",
    "            if len(good_new) > 5 and tracking_active:\n",
    "                # Calculate the median shift\n",
    "                shifts = good_new - good_old\n",
    "                if len(shifts) > 0:\n",
    "                    median_shift = np.median(shifts, axis=0)\n",
    "                    x, y, w, h = [int(v) for v in bbox]\n",
    "                    \n",
    "                    # Apply the shift to the current bbox\n",
    "                    shifted_bbox = (x + int(median_shift[0]), y + int(median_shift[1]), w, h)\n",
    "                    \n",
    "                    # Update Kalman with optical flow information\n",
    "                    center_x = shifted_bbox[0] + shifted_bbox[2]//2\n",
    "                    center_y = shifted_bbox[1] + shifted_bbox[3]//2\n",
    "                    kalman.correct(np.array([[center_x], [center_y]], np.float32))\n",
    "                \n",
    "            # Draw optical flow tracks\n",
    "            for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "                a, b = new.ravel().astype(int)\n",
    "                c, d = old.ravel().astype(int)\n",
    "                cv2.line(frame_display, (a, b), (c, d), (0, 255, 255), 2)\n",
    "                cv2.circle(frame_display, (a, b), 3, (0, 255, 255), -1)\n",
    "            \n",
    "            # Update old_points for next frame\n",
    "            old_points = good_new.reshape(-1, 1, 2)\n",
    "    \n",
    "    # Update old_gray for next optical flow calculation\n",
    "    old_gray = gray.copy()\n",
    "    \n",
    "    # Draw tracking history\n",
    "    for i in range(1, len(bbox_history)):\n",
    "        prev_x, prev_y = bbox_history[i-1][0] + bbox_history[i-1][2]//2, bbox_history[i-1][1] + bbox_history[i-1][3]//2\n",
    "        curr_x, curr_y = bbox_history[i][0] + bbox_history[i][2]//2, bbox_history[i][1] + bbox_history[i][3]//2\n",
    "        cv2.line(frame_display, (prev_x, prev_y), (curr_x, curr_y), (255, 0, 0), 1)\n",
    "    \n",
    "    # Show the result\n",
    "    cv2.imshow(\"Object Tracking\", frame_display)\n",
    "    \n",
    "    # Break on ESC key\n",
    "    if cv2.waitKey(1) == 27:  # ESC key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VISION",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
