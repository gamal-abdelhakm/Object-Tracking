{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo\n",
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "class OcclusionHandlingTrackerGUI:\n",
    "    def __init__(self, root):\n",
    "        # Initialize window\n",
    "        self.root = root\n",
    "        self.root.title(\"Occlusion Handling Tracker\")\n",
    "        self.root.configure(bg=\"#101820\")\n",
    "        self.root.geometry(\"750x700\")\n",
    "        \n",
    "        # Initialize video capture\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        \n",
    "        # Tracking variables\n",
    "        self.tracking = False\n",
    "        self.tracking_lost = False\n",
    "        self.tracker = None\n",
    "        self.bbox = None\n",
    "        self.prev_points = None\n",
    "        self.old_gray = None\n",
    "        self.mask = None\n",
    "        self.predicted_bbox = None\n",
    "        self.occlusion_counter = 0\n",
    "        \n",
    "        # Tracker options\n",
    "        self.tracker_types = {\n",
    "            \"CSRT\": cv2.legacy.TrackerCSRT_create,\n",
    "            \"KCF\": cv2.legacy.TrackerKCF_create, \n",
    "            \"MIL\": cv2.legacy.TrackerMIL_create\n",
    "        }\n",
    "        self.tracker_type = tk.StringVar(value=\"CSRT\")\n",
    "        \n",
    "        # Optical flow parameters\n",
    "        self.lk_params = dict(\n",
    "            winSize=(15, 15),\n",
    "            maxLevel=2,\n",
    "            criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03)\n",
    "        )\n",
    "        \n",
    "        # Occlusion handling parameters\n",
    "        self.occlusion_threshold = 0.4  # Minimum percentage of points needed\n",
    "        self.max_occlusion_frames = 15  # Max frames to predict during occlusion\n",
    "        \n",
    "        # Create UI elements\n",
    "        self.create_ui()\n",
    "        \n",
    "        # Start video loop\n",
    "        self.update()\n",
    "    \n",
    "    def create_ui(self):\n",
    "        # Video display\n",
    "        self.video_lbl = tk.Label(self.root, bg=\"black\")\n",
    "        self.video_lbl.pack(fill=\"both\", expand=True, padx=10, pady=10)\n",
    "        \n",
    "        # Status label\n",
    "        self.status_lbl = tk.Label(\n",
    "            self.root, \n",
    "            text=\"Status: Idle\", \n",
    "            font=(\"Arial\", 15, \"bold\"), \n",
    "            fg=\"white\", \n",
    "            bg=\"#101820\"\n",
    "        )\n",
    "        self.status_lbl.pack(pady=5)\n",
    "        \n",
    "        # Controls frame\n",
    "        control_frame = tk.Frame(self.root, bg=\"#2C3E50\")\n",
    "        control_frame.pack(padx=10, pady=10, fill=\"x\")\n",
    "        \n",
    "        # Tracker selection\n",
    "        tk.Label(\n",
    "            control_frame, \n",
    "            text=\"Select Tracker:\", \n",
    "            font=(\"Arial\", 12, \"bold\"), \n",
    "            fg=\"white\", \n",
    "            bg=\"#2C3E50\"\n",
    "        ).grid(row=0, column=0, padx=5, pady=5)\n",
    "        \n",
    "        tracker_combo = ttk.Combobox(\n",
    "            control_frame, \n",
    "            textvariable=self.tracker_type, \n",
    "            values=list(self.tracker_types.keys()), \n",
    "            state=\"readonly\"\n",
    "        )\n",
    "        tracker_combo.grid(row=0, column=1, padx=5, pady=5)\n",
    "        \n",
    "        # Buttons\n",
    "        tk.Button(\n",
    "            control_frame, \n",
    "            text=\"Select ROI\", \n",
    "            width=12, \n",
    "            command=self.select_roi, \n",
    "            bg=\"#3498DB\", \n",
    "            fg=\"white\", \n",
    "            font=(\"Arial\", 10, \"bold\")\n",
    "        ).grid(row=0, column=2, padx=5, pady=5)\n",
    "        \n",
    "        tk.Button(\n",
    "            control_frame, \n",
    "            text=\"Start Tracking\", \n",
    "            width=12, \n",
    "            command=self.start_tracking, \n",
    "            bg=\"#2ECC71\", \n",
    "            fg=\"white\", \n",
    "            font=(\"Arial\", 10, \"bold\")\n",
    "        ).grid(row=0, column=3, padx=5, pady=5)\n",
    "        \n",
    "        tk.Button(\n",
    "            control_frame, \n",
    "            text=\"Stop Tracking\", \n",
    "            width=12, \n",
    "            command=self.stop_tracking, \n",
    "            bg=\"#E74C3C\", \n",
    "            fg=\"white\", \n",
    "            font=(\"Arial\", 10, \"bold\")\n",
    "        ).grid(row=0, column=4, padx=5, pady=5)\n",
    "        \n",
    "        # Advanced parameters frame\n",
    "        adv_frame = tk.Frame(self.root, bg=\"#2C3E50\")\n",
    "        adv_frame.pack(padx=10, pady=5, fill=\"x\")\n",
    "        \n",
    "        # Occlusion threshold slider\n",
    "        tk.Label(\n",
    "            adv_frame, \n",
    "            text=\"Occlusion Threshold:\", \n",
    "            font=(\"Arial\", 10),\n",
    "            fg=\"white\", \n",
    "            bg=\"#2C3E50\"\n",
    "        ).grid(row=0, column=0, padx=5, pady=5)\n",
    "        \n",
    "        self.occ_threshold_var = tk.DoubleVar(value=self.occlusion_threshold)\n",
    "        occ_threshold_slider = ttk.Scale(\n",
    "            adv_frame, \n",
    "            from_=0.1, \n",
    "            to=0.9,\n",
    "            variable=self.occ_threshold_var, \n",
    "            orient=\"horizontal\", \n",
    "            length=150\n",
    "        )\n",
    "        occ_threshold_slider.grid(row=0, column=1, padx=5, pady=5)\n",
    "        occ_threshold_slider.bind(\"<ButtonRelease-1>\", self.update_parameters)\n",
    "        \n",
    "        tk.Label(\n",
    "            adv_frame, \n",
    "            textvariable=self.occ_threshold_var, \n",
    "            font=(\"Arial\", 10), \n",
    "            fg=\"white\", \n",
    "            bg=\"#2C3E50\", \n",
    "            width=4\n",
    "        ).grid(row=0, column=2, padx=5, pady=5)\n",
    "        \n",
    "        # Max occlusion frames slider\n",
    "        tk.Label(\n",
    "            adv_frame, \n",
    "            text=\"Max Occlusion Frames:\", \n",
    "            font=(\"Arial\", 10), \n",
    "            fg=\"white\", \n",
    "            bg=\"#2C3E50\"\n",
    "        ).grid(row=0, column=3, padx=5, pady=5)\n",
    "        \n",
    "        self.max_occ_frames_var = tk.IntVar(value=self.max_occlusion_frames)\n",
    "        max_occ_frames_slider = ttk.Scale(\n",
    "            adv_frame, \n",
    "            from_=5, \n",
    "            to=30, \n",
    "            variable=self.max_occ_frames_var, \n",
    "            orient=\"horizontal\", \n",
    "            length=150\n",
    "        )\n",
    "        max_occ_frames_slider.grid(row=0, column=4, padx=5, pady=5)\n",
    "        max_occ_frames_slider.bind(\"<ButtonRelease-1>\", self.update_parameters)\n",
    "        \n",
    "        tk.Label(\n",
    "            adv_frame, \n",
    "            textvariable=self.max_occ_frames_var, \n",
    "            font=(\"Arial\", 10), \n",
    "            fg=\"white\", \n",
    "            bg=\"#2C3E50\", \n",
    "            width=4\n",
    "        ).grid(row=0, column=5, padx=5, pady=5)\n",
    "    \n",
    "    def update_parameters(self, event=None):\n",
    "        # Update parameters when sliders change\n",
    "        self.occlusion_threshold = self.occ_threshold_var.get()\n",
    "        self.max_occlusion_frames = self.max_occ_frames_var.get()\n",
    "    \n",
    "    def select_roi(self):\n",
    "        # Pause tracking to select ROI\n",
    "        self.stop_tracking()\n",
    "        \n",
    "        # Get frame for ROI selection\n",
    "        ret, frame = self.cap.read()\n",
    "        if ret:\n",
    "            # Display instruction on frame\n",
    "            cv2.putText(\n",
    "                frame, \n",
    "                \"Select ROI & press ENTER or SPACE\", \n",
    "                (10, 30), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                0.7, \n",
    "                (255, 255, 255), \n",
    "                2\n",
    "            )\n",
    "            \n",
    "            # Get ROI from user\n",
    "            self.bbox = cv2.selectROI(\"Select ROI\", frame, fromCenter=False, showCrosshair=True)\n",
    "            cv2.destroyWindow(\"Select ROI\")\n",
    "            \n",
    "            # Initialize tracking if valid ROI\n",
    "            if self.bbox != (0, 0, 0, 0):\n",
    "                # Initialize tracker based on selected type\n",
    "                self.tracker = self.tracker_types[self.tracker_type.get()]()\n",
    "                self.tracker.init(frame, self.bbox)\n",
    "                \n",
    "                # Initialize optical flow\n",
    "                frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                self.old_gray = frame_gray\n",
    "                self.mask = np.zeros_like(frame)\n",
    "                \n",
    "                # Create ROI mask for feature detection\n",
    "                x, y, w, h = [int(v) for v in self.bbox]\n",
    "                roi_mask = np.zeros_like(frame_gray)\n",
    "                roi_mask[y:y+h, x:x+w] = 255\n",
    "                \n",
    "                # Detect good features in ROI\n",
    "                self.prev_points = cv2.goodFeaturesToTrack(\n",
    "                    frame_gray, \n",
    "                    mask=roi_mask, \n",
    "                    maxCorners=200, \n",
    "                    qualityLevel=0.01, \n",
    "                    minDistance=7, \n",
    "                    blockSize=7\n",
    "                )\n",
    "                \n",
    "                # Set initial prediction\n",
    "                self.predicted_bbox = (x, y, w, h)\n",
    "                self.tracking_lost = False\n",
    "                self.occlusion_counter = 0\n",
    "                \n",
    "                # Update status\n",
    "                self.status_lbl.config(text=\"Status: ROI Selected\", fg=\"lime\")\n",
    "    \n",
    "    def start_tracking(self):\n",
    "        if self.bbox is not None:\n",
    "            self.tracking = True\n",
    "            self.status_lbl.config(text=\"Status: Tracking\", fg=\"lime\")\n",
    "    \n",
    "    def stop_tracking(self):\n",
    "        self.tracking = False\n",
    "        self.status_lbl.config(text=\"Status: Stopped\", fg=\"orange\")\n",
    "    \n",
    "    def update(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if ret:\n",
    "            frame_displayed = frame.copy()\n",
    "            \n",
    "            if self.tracking and self.bbox is not None:\n",
    "                frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                \n",
    "                if not self.tracking_lost:\n",
    "                    # Update CSRT tracker\n",
    "                    success, bbox = self.tracker.update(frame)\n",
    "                    \n",
    "                    if success:\n",
    "                        # Extract bbox coordinates\n",
    "                        x, y, w, h = [int(v) for v in bbox]\n",
    "                        \n",
    "                        # Draw bbox\n",
    "                        cv2.rectangle(frame_displayed, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                        cv2.putText(\n",
    "                            frame_displayed, \n",
    "                            \"Tracking\", \n",
    "                            (x, y - 10), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                            0.7, \n",
    "                            (0, 255, 0), \n",
    "                            2\n",
    "                        )\n",
    "                        \n",
    "                        # Update feature points when tracking is good\n",
    "                        roi_mask = np.zeros_like(self.old_gray)\n",
    "                        roi_mask[y:y+h, x:x+w] = 255\n",
    "                        self.prev_points = cv2.goodFeaturesToTrack(\n",
    "                            self.old_gray, \n",
    "                            mask=roi_mask, \n",
    "                            maxCorners=200, \n",
    "                            qualityLevel=0.01, \n",
    "                            minDistance=7, \n",
    "                            blockSize=7\n",
    "                        )\n",
    "                        self.predicted_bbox = (x, y, w, h)\n",
    "                        self.occlusion_counter = 0\n",
    "                        self.status_lbl.config(text=\"Status: Tracking\", fg=\"lime\")\n",
    "                    else:\n",
    "                        self.tracking_lost = True\n",
    "                        self.status_lbl.config(text=\"Status: Occlusion Detected\", fg=\"#FFA500\")\n",
    "                \n",
    "                # Use optical flow when tracking is lost or occluded\n",
    "                if self.tracking_lost and self.prev_points is not None and len(self.prev_points) > 0:\n",
    "                    # Calculate optical flow\n",
    "                    new_points, status, err = cv2.calcOpticalFlowPyrLK(\n",
    "                        self.old_gray, \n",
    "                        frame_gray, \n",
    "                        self.prev_points, \n",
    "                        None, \n",
    "                        **self.lk_params\n",
    "                    )\n",
    "                    \n",
    "                    if new_points is not None:\n",
    "                        # Filter valid points\n",
    "                        good_new = new_points[status == 1]\n",
    "                        good_old = self.prev_points[status == 1]\n",
    "                        \n",
    "                        # Check if enough points remain\n",
    "                        if len(good_new) > self.occlusion_threshold * len(self.prev_points):\n",
    "                            # Calculate median displacement\n",
    "                            displacement = np.median(good_new - good_old, axis=0)\n",
    "                            \n",
    "                            # Update predicted position\n",
    "                            px, py, pw, ph = self.predicted_bbox\n",
    "                            new_x = int(px + displacement[0])\n",
    "                            new_y = int(py + displacement[1])\n",
    "                            self.predicted_bbox = (new_x, new_y, pw, ph)\n",
    "                            \n",
    "                            # Draw predicted bbox\n",
    "                            x, y, w, h = self.predicted_bbox\n",
    "                            cv2.rectangle(frame_displayed, (x, y), (x + w, y + h), (0, 255, 255), 2)\n",
    "                            cv2.putText(\n",
    "                                frame_displayed, \n",
    "                                \"Occlusion Handling\", \n",
    "                                (x, y - 10), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                                0.7, \n",
    "                                (0, 255, 255), \n",
    "                                2\n",
    "                            )\n",
    "                            \n",
    "                            # Update tracker position\n",
    "                            self.tracker.init(frame, self.predicted_bbox)\n",
    "                            self.occlusion_counter += 1\n",
    "                            \n",
    "                            # Reset if occlusion lasts too long\n",
    "                            if self.occlusion_counter > self.max_occlusion_frames:\n",
    "                                self.tracking_lost = True\n",
    "                                cv2.putText(\n",
    "                                    frame_displayed, \n",
    "                                    \"RE-INITIALIZE TRACKER!\", \n",
    "                                    (50, 50), \n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                                    1, \n",
    "                                    (0, 0, 255), \n",
    "                                    2\n",
    "                                )\n",
    "                                self.status_lbl.config(text=\"Status: Track Lost - Reselect ROI\", fg=\"red\")\n",
    "                        else:\n",
    "                            self.tracking_lost = True\n",
    "                            self.status_lbl.config(text=\"Status: Track Lost - Reselect ROI\", fg=\"red\")\n",
    "                        \n",
    "                        # Draw optical flow vectors\n",
    "                        self.mask = np.zeros_like(frame)\n",
    "                        for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "                            a, b = new.ravel()\n",
    "                            c, d = old.ravel()\n",
    "                            self.mask = cv2.line(\n",
    "                                self.mask, \n",
    "                                (int(a), int(b)), \n",
    "                                (int(c), int(d)), \n",
    "                                (0, 255, 0), \n",
    "                                2\n",
    "                            )\n",
    "                            frame_displayed = cv2.circle(\n",
    "                                frame_displayed, \n",
    "                                (int(a), int(b)), \n",
    "                                3, \n",
    "                                (0, 255, 0), \n",
    "                                -1\n",
    "                            )\n",
    "                        \n",
    "                        # Save good points for next iteration\n",
    "                        self.prev_points = good_new.reshape(-1, 1, 2)\n",
    "                \n",
    "                # Reset tracking if completely lost or not enough points\n",
    "                if (self.tracking_lost and self.occlusion_counter > self.max_occlusion_frames) or \\\n",
    "                   (self.prev_points is not None and len(self.prev_points) < 10):\n",
    "                    # Prompt users to reselect ROI\n",
    "                    cv2.putText(\n",
    "                        frame_displayed, \n",
    "                        \"Track Lost - Click 'Select ROI'\", \n",
    "                        (50, 50), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                        1, \n",
    "                        (0, 0, 255), \n",
    "                        2\n",
    "                    )\n",
    "                    self.status_lbl.config(text=\"Status: Track Lost - Reselect ROI\", fg=\"red\")\n",
    "                \n",
    "                # Update previous frame\n",
    "                self.old_gray = frame_gray.copy()\n",
    "                \n",
    "                # Combine optical flow visualization\n",
    "                frame_displayed = cv2.add(frame_displayed, self.mask)\n",
    "            \n",
    "            # Convert to ImageTk format and display\n",
    "            img = cv2.cvtColor(frame_displayed, cv2.COLOR_BGR2RGB)\n",
    "            img = Image.fromarray(img)\n",
    "            imgtk = ImageTk.PhotoImage(image=img)\n",
    "            self.video_lbl.imgtk = imgtk\n",
    "            self.video_lbl.configure(image=imgtk)\n",
    "        \n",
    "        # Schedule next update\n",
    "        self.root.after(15, self.update)\n",
    "    \n",
    "    def cleanup(self):\n",
    "        # Release resources\n",
    "        if self.cap.isOpened():\n",
    "            self.cap.release()\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    root = tk.Tk()\n",
    "    app = OcclusionHandlingTrackerGUI(root)\n",
    "    \n",
    "    # Set cleanup on window close\n",
    "    root.protocol(\"WM_DELETE_WINDOW\", lambda: [app.cleanup(), root.destroy()])\n",
    "    \n",
    "    # Start main loop\n",
    "    root.mainloop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\dxt.cpp:3506: error: (-215:Assertion failed) type == CV_32FC1 || type == CV_32FC2 || type == CV_64FC1 || type == CV_64FC2 in function 'cv::dft'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Initialize CSRT tracker\u001b[39;00m\n\u001b[0;32m     12\u001b[0m tracker \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mlegacy\u001b[38;5;241m.\u001b[39mTrackerCSRT_create()\n\u001b[1;32m---> 13\u001b[0m \u001b[43mtracker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Optical flow parameters\u001b[39;00m\n\u001b[0;32m     16\u001b[0m lk_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(winSize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m15\u001b[39m),maxLevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,criteria\u001b[38;5;241m=\u001b[39m(cv2\u001b[38;5;241m.\u001b[39mTERM_CRITERIA_EPS \u001b[38;5;241m|\u001b[39m cv2\u001b[38;5;241m.\u001b[39mTERM_CRITERIA_COUNT, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m0.03\u001b[39m))\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\dxt.cpp:3506: error: (-215:Assertion failed) type == CV_32FC1 || type == CV_32FC2 || type == CV_64FC1 || type == CV_64FC2 in function 'cv::dft'\n"
     ]
    }
   ],
   "source": [
    "# CSRT Tracker & Optical Flow & Occlusion handling\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Select object to track (first frame)\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame = cap.read()\n",
    "bbox = cv2.selectROI(\"Select Object\", frame)\n",
    "cv2.destroyWindow(\"Select Object\")\n",
    "\n",
    "# Initialize CSRT tracker\n",
    "tracker = cv2.legacy.TrackerCSRT_create()\n",
    "tracker.init(frame, bbox)\n",
    "\n",
    "# Optical flow parameters\n",
    "lk_params = dict(winSize=(15, 15),maxLevel=2,criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Iocclusion handling\n",
    "occlusion_threshold = 0.4  # Minimum percentage of points needed to consider tracking valid\n",
    "occlusion_counter = 0\n",
    "max_occlusion_frames = 15  # Max frames to predict during occlusion\n",
    "\n",
    "# Initialize feature points for optical flow\n",
    "old_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "mask = np.zeros_like(frame)\n",
    "prev_points = cv2.goodFeaturesToTrack(old_gray, maxCorners=200, qualityLevel=0.01, minDistance=7, blockSize=7)\n",
    "\n",
    "# Convert bbox to integers\n",
    "x, y, w, h = [int(v) for v in bbox]\n",
    "\n",
    "# Create ROI mask for feature point selection\n",
    "roi_mask = np.zeros_like(old_gray)\n",
    "roi_mask[y:y+h, x:x+w] = 255\n",
    "prev_points = cv2.goodFeaturesToTrack(old_gray, mask=roi_mask, maxCorners=200, qualityLevel=0.01, minDistance=7, blockSize=7)\n",
    "\n",
    "# Initialize predicted position\n",
    "predicted_bbox = (x, y, w, h)\n",
    "tracking_lost = False\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    if not tracking_lost:\n",
    "        # Update CSRT tracker\n",
    "        success, bbox = tracker.update(frame)\n",
    "        \n",
    "        if success:\n",
    "            # Update feature points when tracking is good\n",
    "            x, y, w, h = [int(v) for v in bbox]\n",
    "            roi_mask = np.zeros_like(old_gray)\n",
    "            roi_mask[y:y+h, x:x+w] = 255\n",
    "            prev_points = cv2.goodFeaturesToTrack(old_gray, mask=roi_mask, maxCorners=200, qualityLevel=0.01, minDistance=7, blockSize=7)\n",
    "            predicted_bbox = (x, y, w, h)\n",
    "            occlusion_counter = 0\n",
    "        else:\n",
    "            tracking_lost = True\n",
    "\n",
    "    # Use optical flow when tracking is lost or occluded\n",
    "    if tracking_lost or (prev_points is not None and len(prev_points) > 0):\n",
    "        # Calculate optical flow\n",
    "        new_points, status, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, prev_points, None, **lk_params)\n",
    "        if new_points is not None:\n",
    "            # Filter valid points\n",
    "            good_new = new_points[status == 1]\n",
    "            good_old = prev_points[status == 1]\n",
    "            \n",
    "            # Check if enough points remain\n",
    "            if len(good_new) > occlusion_threshold * len(prev_points):\n",
    "                displacement = np.median(good_new - good_old, axis=0) # Calculate median displacement\n",
    "                \n",
    "                # Update predicted position\n",
    "                px, py, pw, ph = predicted_bbox\n",
    "                new_x = int(px + displacement[0])\n",
    "                new_y = int(py + displacement[1])\n",
    "                predicted_bbox = (new_x, new_y, pw, ph)\n",
    "                \n",
    "                # Draw predicted bbox\n",
    "                x, y, w, h = predicted_bbox\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 255), 2)\n",
    "                cv2.putText(frame, \"Occlusion Handling\", (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "                \n",
    "                # Update tracker position\n",
    "                tracker.init(frame, predicted_bbox)\n",
    "                occlusion_counter += 1\n",
    "                \n",
    "                # Reset if occlusion lasts too long\n",
    "                if occlusion_counter > max_occlusion_frames:\n",
    "                    tracking_lost = True\n",
    "                    cv2.putText(frame, \"RE-INITIALIZE TRACKER!\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            else:\n",
    "                tracking_lost = True\n",
    "\n",
    "            # Draw optical flow vectors\n",
    "            for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
    "                a, b = new.ravel()\n",
    "                c, d = old.ravel()\n",
    "                mask = cv2.line(mask, (int(a), int(b)), (int(c), int(d)), (0, 255, 0), 2)\n",
    "                frame = cv2.circle(frame, (int(a), int(b)), 5, (0, 255, 0), -1)\n",
    "                \n",
    "            prev_points = good_new.reshape(-1, 1, 2)\n",
    "            \n",
    "    # Reset tracking if completely lost\n",
    "    if tracking_lost:\n",
    "        bbox = cv2.selectROI(\"Select Object\", frame, False)\n",
    "        cv2.destroyWindow(\"Select Object\")\n",
    "        tracker = cv2.legacy.TrackerCSRT_create()\n",
    "        tracker.init(frame, bbox)\n",
    "        tracking_lost = False\n",
    "        prev_points = None\n",
    "\n",
    "    # Update previous frame and points\n",
    "    old_gray = frame_gray.copy()\n",
    "    if prev_points is not None and len(prev_points) < 10:\n",
    "        tracking_lost = True\n",
    "\n",
    "    # Combine optical flow visualization\n",
    "    img = cv2.add(frame, mask)\n",
    "\n",
    "    cv2.imshow(\"Occlusion Handling Tracker\", img)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Logic:\n",
    "# CSRT Tracker & Optical Flow & Kalman Filter  & Tracking History\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame = cap.read()\n",
    "bbox = cv2.selectROI(\"Select Object\", frame, False)\n",
    "\n",
    "tracker = cv2.TrackerCSRT_create()\n",
    "tracker.init(frame, bbox)\n",
    "prev_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "kalman = cv2.KalmanFilter(4, 2)\n",
    "kalman.measurementMatrix = np.array([[1, 0, 0, 0],[0, 1, 0, 0]], np.float32)\n",
    "kalman.transitionMatrix = np.array([[1, 0, 1, 0],[0, 1, 0, 1],[0, 0, 1, 0],[0, 0, 0, 1]], np.float32)\n",
    "kalman.processNoiseCov = np.eye(4, dtype=np.float32) * 0.03\n",
    "\n",
    "tracking_history = deque(maxlen=10)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    success, bbox = tracker.update(frame)\n",
    "\n",
    "    if success:\n",
    "        x, y, w, h = [int(v) for v in bbox]\n",
    "        center_x, center_y = x + w // 2, y + h // 2\n",
    "\n",
    "        measurement = np.array([[np.float32(center_x)], [np.float32(center_y)]])\n",
    "        kalman.correct(measurement)\n",
    "\n",
    "        tracking_history.append((center_x, center_y, w, h))\n",
    "\n",
    "    else:\n",
    "        if len(tracking_history) > 1:\n",
    "            p0 = np.array([[tracking_history[-2][:2]]], dtype=np.float32)\n",
    "            p1, st, err = cv2.calcOpticalFlowPyrLK(prev_gray, gray, p0, None)\n",
    "\n",
    "            if p1 is not None and st[0] == 1:\n",
    "                pred_x, pred_y = int(p1[0][0][0]), int(p1[0][0][1])\n",
    "            else:\n",
    "                prediction = kalman.predict()\n",
    "                pred_x, pred_y = int(prediction[0]), int(prediction[1])\n",
    "\n",
    "            bbox = (pred_x - w // 2, pred_y - h // 2, w, h)\n",
    "            tracker = cv2.TrackerCSRT_create()\n",
    "            tracker.init(frame, bbox)\n",
    "\n",
    "    prev_gray = gray.copy()\n",
    "\n",
    "    if len(tracking_history) > 0:\n",
    "        last_x, last_y, last_w, last_h = tracking_history[-1]\n",
    "        cv2.rectangle(frame, (last_x - last_w // 2, last_y - last_h // 2), (last_x + last_w // 2, last_y + last_h // 2), (0, 255, 0), 2)\n",
    "\n",
    "    for i in range(1, len(tracking_history)):\n",
    "        cv2.line(frame, tracking_history[i - 1][:2], tracking_history[i][:2], (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow(\"Tracking\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try OpticalFlow & recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "# Setup window\n",
    "win = tk.Tk()\n",
    "win.title(\"Object Tracking\")\n",
    "win.configure(bg=\"#101820\")\n",
    "win.geometry(\"1100x600\")\n",
    "\n",
    "# Tracker options\n",
    "types = {\"MIL\": cv2.TrackerMIL_create, \"KCF\": cv2.TrackerKCF_create, \"CSRT\": cv2.TrackerCSRT_create}\n",
    "tracker_type = tk.StringVar(value=\"CSRT\")\n",
    "\n",
    "# Tracking enhancement options\n",
    "use_optical_flow = tk.BooleanVar(value=True)\n",
    "recovery_mode = tk.BooleanVar(value=True)\n",
    "\n",
    "# Video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "tracker, bbox, tracking = None, None, False\n",
    "\n",
    "# Optical flow parameters\n",
    "feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
    "lk_params = dict(winSize=(15, 15), maxLevel=2, \n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Tracking variables\n",
    "prev_frame = None\n",
    "prev_pts = None\n",
    "tracking_history = []  # Store recent tracking positions\n",
    "recovery_frames = 0    # Count frames since tracking was lost\n",
    "max_recovery_frames = 30  # Maximum frames to attempt recovery\n",
    "\n",
    "# UI Elements\n",
    "video_lbl = tk.Label(win, bg=\"black\")\n",
    "video_lbl.pack(fill=\"both\", expand=True, padx=10, pady=10)\n",
    "status_lbl = tk.Label(win, text=\"Idle\", font=(\"Arial\", 15, \"bold\"), fg=\"white\", bg=\"#101820\")\n",
    "status_lbl.pack(pady=5)\n",
    "\n",
    "def select_roi():\n",
    "    global bbox, tracker, tracking, prev_frame, prev_pts\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        cv2.putText(frame, \"Select ROI & press ESC\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        bbox = cv2.selectROI(\"Select ROI\", frame, fromCenter=False, showCrosshair=True)\n",
    "        cv2.destroyWindow(\"Select ROI\")\n",
    "        if bbox != (0, 0, 0, 0):\n",
    "            tracker = types[tracker_type.get()]()\n",
    "            tracker.init(frame, bbox)\n",
    "            tracking = True\n",
    "            status_lbl.config(text=\"Status: Tracking\", fg=\"lime\")\n",
    "            \n",
    "            # Initialize optical flow\n",
    "            prev_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            x, y, w, h = map(int, bbox)\n",
    "            roi = prev_frame[y:y+h, x:x+w]\n",
    "            prev_pts = cv2.goodFeaturesToTrack(roi, mask=None, **feature_params)\n",
    "            if prev_pts is not None:\n",
    "                prev_pts = prev_pts + np.array([x, y], dtype=np.float32)  # Adjust coordinates to global frame\n",
    "            tracking_history.clear()\n",
    "\n",
    "def start():\n",
    "    global tracking\n",
    "    tracking = True\n",
    "    status_lbl.config(text=\"Status: Tracking\", fg=\"lime\")\n",
    "\n",
    "def stop():\n",
    "    global tracking\n",
    "    tracking = False\n",
    "    status_lbl.config(text=\"Status: Stopped\", fg=\"red\")\n",
    "\n",
    "def reset_tracker():\n",
    "    global tracker, bbox, tracking, prev_frame, prev_pts, tracking_history, recovery_frames\n",
    "    tracking = False\n",
    "    tracker = None\n",
    "    bbox = None\n",
    "    prev_frame = None\n",
    "    prev_pts = None\n",
    "    tracking_history.clear()\n",
    "    recovery_frames = 0\n",
    "    status_lbl.config(text=\"Status: Reset\", fg=\"orange\")\n",
    "\n",
    "def update_tracker_with_optical_flow(frame, gray_frame):\n",
    "    global prev_frame, prev_pts, bbox\n",
    "    \n",
    "    if prev_frame is None or prev_pts is None or len(prev_pts) < 5:\n",
    "        return False, bbox\n",
    "    \n",
    "    # Calculate optical flow\n",
    "    next_pts, status, _ = cv2.calcOpticalFlowPyrLK(prev_frame, gray_frame, prev_pts, None, **lk_params)\n",
    "    \n",
    "    # Filter good points\n",
    "    if next_pts is not None:\n",
    "        good_new = next_pts[status == 1]\n",
    "        good_old = prev_pts[status == 1]\n",
    "        \n",
    "        if len(good_new) > 5:  # Enough points to estimate movement\n",
    "            # Calculate bounding box movement\n",
    "            movement = np.mean(good_new - good_old, axis=0)\n",
    "            x, y, w, h = bbox\n",
    "            \n",
    "            # Update bounding box position\n",
    "            new_x = x + movement[0]\n",
    "            new_y = y + movement[1]\n",
    "            \n",
    "            # Update previous points for next iteration\n",
    "            prev_pts = good_new.reshape(-1, 1, 2)\n",
    "            prev_frame = gray_frame.copy()\n",
    "            \n",
    "            # Update bbox\n",
    "            bbox = (new_x, new_y, w, h)\n",
    "            return True, bbox\n",
    "    \n",
    "    # Not enough points to track\n",
    "    return False, bbox\n",
    "\n",
    "def attempt_recovery(frame, gray_frame):\n",
    "    global bbox, tracker, tracking_history, recovery_frames\n",
    "    \n",
    "    if len(tracking_history) < 5:\n",
    "        return False, bbox\n",
    "    \n",
    "    # Predict position based on recent movement\n",
    "    recent_positions = np.array(tracking_history[-5:])\n",
    "    if len(recent_positions) >= 2:\n",
    "        # Calculate average movement direction and speed\n",
    "        movements = recent_positions[1:] - recent_positions[:-1]\n",
    "        avg_movement = np.mean(movements, axis=0)\n",
    "        \n",
    "        # Predict new position\n",
    "        last_pos = recent_positions[-1]\n",
    "        predicted_pos = last_pos + avg_movement * (recovery_frames * 0.5 + 1)  # Scale movement by recovery time\n",
    "        \n",
    "        x, y, w, h = bbox\n",
    "        new_bbox = (predicted_pos[0], predicted_pos[1], w, h)\n",
    "        \n",
    "        # Reinitialize tracker at predicted position\n",
    "        tracker = types[tracker_type.get()]()\n",
    "        tracker.init(frame, new_bbox)\n",
    "        \n",
    "        recovery_frames += 1\n",
    "        return True, new_bbox\n",
    "    \n",
    "    return False, bbox\n",
    "\n",
    "def update():\n",
    "    global tracking, tracker, bbox, prev_frame, prev_pts, tracking_history, recovery_frames\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        win.after(15, update)\n",
    "        return\n",
    "    \n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    if tracking and tracker:\n",
    "        tracking_success = False\n",
    "        of_success = False\n",
    "        \n",
    "        # 1. Try CSRT tracker first\n",
    "        if tracker:\n",
    "            tracking_success, new_bbox = tracker.update(frame)\n",
    "        \n",
    "        # 2. Apply optical flow if enabled\n",
    "        if use_optical_flow.get():\n",
    "            of_success, of_bbox = update_tracker_with_optical_flow(frame, gray_frame)\n",
    "            \n",
    "            # Decide which result to use\n",
    "            if tracking_success and of_success:\n",
    "                # Blend CSRT and optical flow results (weighted average)\n",
    "                csrt_weight = 0.7\n",
    "                of_weight = 0.3\n",
    "                x1, y1, w1, h1 = new_bbox\n",
    "                x2, y2, w2, h2 = of_bbox\n",
    "                \n",
    "                blended_x = x1 * csrt_weight + x2 * of_weight\n",
    "                blended_y = y1 * csrt_weight + y2 * of_weight\n",
    "                bbox = (blended_x, blended_y, w1, h1)  # Keep original width/height\n",
    "                \n",
    "                # Update optical flow points occasionally for long-term stability\n",
    "                if len(tracking_history) % 10 == 0:\n",
    "                    x, y, w, h = map(int, bbox)\n",
    "                    roi = gray_frame[max(0, y):min(frame.shape[0], y+h), \n",
    "                                    max(0, x):min(frame.shape[1], x+w)]\n",
    "                    if roi.size > 0:\n",
    "                        pts = cv2.goodFeaturesToTrack(roi, mask=None, **feature_params)\n",
    "                        if pts is not None and pts.size > 0:\n",
    "                            prev_pts = pts + np.array([x, y], dtype=np.float32)\n",
    "                            prev_frame = gray_frame.copy()\n",
    "            elif tracking_success:\n",
    "                bbox = new_bbox\n",
    "            elif of_success:\n",
    "                bbox = of_bbox\n",
    "                \n",
    "        elif tracking_success:\n",
    "            bbox = new_bbox\n",
    "        \n",
    "        # Store tracking history (for recovery)\n",
    "        if tracking_success or of_success:\n",
    "            x, y, w, h = map(float, bbox)\n",
    "            center_x, center_y = x + w/2, y + h/2\n",
    "            tracking_history.append((center_x, center_y))\n",
    "            if len(tracking_history) > 30:  # Keep last 30 positions\n",
    "                tracking_history.pop(0)\n",
    "            \n",
    "            recovery_frames = 0\n",
    "            status_lbl.config(text=\"Status: Tracking\", fg=\"lime\")\n",
    "        \n",
    "        # Attempt recovery if tracking lost\n",
    "        elif recovery_mode.get() and recovery_frames < max_recovery_frames:\n",
    "            recovery_success, recovery_bbox = attempt_recovery(frame, gray_frame)\n",
    "            if recovery_success:\n",
    "                bbox = recovery_bbox\n",
    "                status_lbl.config(text=f\"Status: Recovering ({recovery_frames}/{max_recovery_frames})\", fg=\"orange\")\n",
    "            else:\n",
    "                status_lbl.config(text=\"Status: Lost Tracking\", fg=\"red\")\n",
    "        else:\n",
    "            status_lbl.config(text=\"Status: Lost Tracking\", fg=\"red\")\n",
    "            \n",
    "        # Draw tracking information on frame\n",
    "        if bbox is not None:\n",
    "            x, y, w, h = map(int, bbox)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            \n",
    "            if tracking_success:\n",
    "                label = \"Tracking (CSRT)\"\n",
    "            elif of_success:\n",
    "                label = \"Tracking (OptFlow)\"\n",
    "            elif recovery_frames > 0:\n",
    "                label = f\"Recovering ({recovery_frames})\"\n",
    "            else:\n",
    "                label = \"Lost\"\n",
    "                \n",
    "            cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "            \n",
    "            # Draw tracking history\n",
    "            if len(tracking_history) > 1:\n",
    "                for i in range(1, len(tracking_history)):\n",
    "                    pt1 = tuple(map(int, tracking_history[i-1]))\n",
    "                    pt2 = tuple(map(int, tracking_history[i]))\n",
    "                    cv2.line(frame, pt1, pt2, (0, 0, 255), 1)\n",
    "    \n",
    "    # Display frame\n",
    "    img = ImageTk.PhotoImage(Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)))\n",
    "    video_lbl.imgtk = img\n",
    "    video_lbl.configure(image=img)\n",
    "    \n",
    "    win.after(33, update)\n",
    "\n",
    "# Controls\n",
    "frame = tk.Frame(win, bg=\"#2C3E50\")\n",
    "frame.pack(padx=10, pady=10)\n",
    "tk.Label(frame, text=\"Select Tracker:\", font=(\"Arial\", 12, \"bold\"), fg=\"white\", bg=\"#2C3E50\").grid(row=0, column=0, padx=5, pady=5)\n",
    "tt = ttk.Combobox(frame, textvariable=tracker_type, values=list(types.keys()), state=\"readonly\").grid(row=0, column=1, padx=5, pady=5)\n",
    "tk.Button(frame, text=\"Select ROI\", width=12, command=select_roi, bg=\"#3498DB\", fg=\"white\", font=(\"Arial\", 10, \"bold\")).grid(row=0, column=2, padx=5, pady=5)\n",
    "tk.Button(frame, text=\"Start Tracking\", width=12, command=start, bg=\"#2ECC71\", fg=\"white\", font=(\"Arial\", 10, \"bold\")).grid(row=0, column=3, padx=5, pady=5)\n",
    "tk.Button(frame, text=\"Stop Tracking\", width=12, command=stop, bg=\"#E74C3C\", fg=\"white\", font=(\"Arial\", 10, \"bold\")).grid(row=0, column=4, padx=5, pady=5)\n",
    "tk.Button(frame, text=\"Reset\", width=12, command=reset_tracker, bg=\"#F39C12\", fg=\"white\", font=(\"Arial\", 10, \"bold\")).grid(row=0, column=5, padx=5, pady=5)\n",
    "tk.Checkbutton(frame, text=\"Use Optical Flow\", variable=use_optical_flow, fg=\"white\", bg=\"#2C3E50\", selectcolor=\"#3498DB\", font=(\"Arial\", 10)).grid(row=0, column=6, padx=15, pady=5)\n",
    "tk.Checkbutton(frame, text=\"Auto Recovery Mode\", variable=recovery_mode,fg=\"white\", bg=\"#2C3E50\", selectcolor=\"#3498DB\", font=(\"Arial\", 10)).grid(row=0, column=7, padx=15, pady=5)\n",
    "\n",
    "# Main loop\n",
    "update()\n",
    "win.mainloop()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try kalman filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gemy2\\AppData\\Local\\Temp\\ipykernel_11808\\4170823917.py:111: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  pred_x, pred_y = int(prediction[0]), int(prediction[1])\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "# Setup window\n",
    "win = tk.Tk()\n",
    "win.title(\"Object Tracking with Kalman Filter\")\n",
    "win.configure(bg=\"#101820\")\n",
    "win.geometry(\"1000x650\")\n",
    "\n",
    "# Tracker options\n",
    "types = {\n",
    "    \"MIL\": cv2.TrackerMIL_create, \n",
    "    \"KCF\": cv2.TrackerKCF_create, \n",
    "    \"CSRT\": cv2.TrackerCSRT_create\n",
    "}\n",
    "tracker_type = tk.StringVar(value=\"CSRT\")\n",
    "\n",
    "# Video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "tracker, bbox, tracking = None, None, False\n",
    "use_kalman = tk.BooleanVar(value=True)\n",
    "\n",
    "# Kalman Filter setup\n",
    "kalman = cv2.KalmanFilter(4, 2)\n",
    "kalman.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)\n",
    "kalman.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)\n",
    "kalman.processNoiseCov = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32) * 0.03\n",
    "kalman_initialized = False\n",
    "\n",
    "# UI Elements\n",
    "video_lbl = tk.Label(win, bg=\"black\")\n",
    "video_lbl.pack(fill=\"both\", expand=True)\n",
    "status_lbl = tk.Label(win, text=\"Idle\", font=(\"Arial\", 15, \"bold\"), fg=\"white\", bg=\"#101820\")\n",
    "status_lbl.pack()\n",
    "\n",
    "\n",
    "\n",
    "def select_roi():\n",
    "    global bbox, tracker, tracking, kalman_initialized\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        cv2.putText(frame, \"Select ROI & press ENTER\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        bbox = cv2.selectROI(\"Select ROI\", frame, fromCenter=False, showCrosshair=True)\n",
    "        cv2.destroyWindow(\"Select ROI\")\n",
    "        if bbox != (0, 0, 0, 0):\n",
    "            x, y, w, h = bbox\n",
    "            center_x = x + w/2\n",
    "            center_y = y + h/2\n",
    "            \n",
    "            # Initialize Kalman filter with object center\n",
    "            kalman.statePre = np.array([[center_x], [center_y], [0], [0]], np.float32)\n",
    "            kalman.statePost = np.array([[center_x], [center_y], [0], [0]], np.float32)\n",
    "            kalman_initialized = True\n",
    "            \n",
    "            # Initialize tracker\n",
    "            tracker = types[tracker_type.get()]()\n",
    "            tracker.init(frame, bbox)\n",
    "            tracking = True\n",
    "            status_lbl.config(text=\"Status: Tracking\", fg=\"lime\")\n",
    "\n",
    "def start():\n",
    "    global tracking\n",
    "    if bbox is not None:\n",
    "        tracking = True\n",
    "        status_lbl.config(text=\"Status: Tracking\", fg=\"lime\")\n",
    "\n",
    "def stop():\n",
    "    global tracking\n",
    "    tracking = False\n",
    "    status_lbl.config(text=\"Status: Stopped\", fg=\"red\")\n",
    "\n",
    "def reset_kalman():\n",
    "    global kalman_initialized\n",
    "    kalman_initialized = False\n",
    "\n",
    "def update():\n",
    "    global kalman_initialized, bbox\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        if tracking and tracker:\n",
    "            success, new_bbox = tracker.update(frame)\n",
    "            \n",
    "            if success:\n",
    "                # Get current position\n",
    "                x, y, w, h = map(int, new_bbox)\n",
    "                center_x = x + w/2\n",
    "                center_y = y + h/2\n",
    "                \n",
    "                # Draw tracker result in green\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                cv2.circle(frame, (int(center_x), int(center_y)), 5, (0, 255, 0), -1)\n",
    "                cv2.putText(frame, \"Tracker\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                \n",
    "                # Use Kalman filter if enabled\n",
    "                if use_kalman.get():\n",
    "                    if not kalman_initialized:\n",
    "                        # Initialize Kalman with current position\n",
    "                        kalman.statePre = np.array([[center_x], [center_y], [0], [0]], np.float32)\n",
    "                        kalman.statePost = np.array([[center_x], [center_y], [0], [0]], np.float32)\n",
    "                        kalman_initialized = True\n",
    "                    \n",
    "                    # Correct using measurement\n",
    "                    measurement = np.array([[center_x], [center_y]], np.float32)\n",
    "                    kalman.correct(measurement)\n",
    "                    \n",
    "                    # Predict next position\n",
    "                    prediction = kalman.predict()\n",
    "                    pred_x, pred_y = int(prediction[0]), int(prediction[1])\n",
    "                    \n",
    "                    # Draw Kalman prediction in blue\n",
    "                    cv2.circle(frame, (pred_x, pred_y), 5, (255, 0, 0), -1)\n",
    "                    cv2.putText(frame, \"Kalman\", (pred_x + 10, pred_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "                    \n",
    "                    # Draw a line connecting actual position to prediction\n",
    "                    cv2.line(frame, (int(center_x), int(center_y)), (pred_x, pred_y), (255, 255, 0), 1)\n",
    "                    \n",
    "                    # Update status with position info\n",
    "                    status_lbl.config(text=f\"Tracking: Actual ({int(center_x)},{int(center_y)}) | Predicted ({pred_x},{pred_y})\", fg=\"lime\")\n",
    "                else:\n",
    "                    status_lbl.config(text=f\"Tracking: Position ({int(center_x)},{int(center_y)})\", fg=\"lime\")\n",
    "            else:\n",
    "                if use_kalman.get() and kalman_initialized:\n",
    "                    # If tracking is lost, still predict with Kalman\n",
    "                    prediction = kalman.predict()\n",
    "                    pred_x, pred_y = int(prediction[0]), int(prediction[1])\n",
    "                    \n",
    "                    # Draw only Kalman prediction in blue\n",
    "                    cv2.circle(frame, (pred_x, pred_y), 8, (255, 0, 0), -1)\n",
    "                    cv2.putText(frame, \"Kalman (Lost Tracking)\", (pred_x + 10, pred_y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "                    status_lbl.config(text=f\"Lost Tracking: Kalman predicting ({pred_x},{pred_y})\", fg=\"orange\")\n",
    "                    \n",
    "                    # Update the tracker with Kalman's prediction if confidence is lost\n",
    "                    pred_w, pred_h = (bbox[2], bbox[3]) if bbox else (50, 50)\n",
    "                    new_bbox = (pred_x - pred_w//2, pred_y - pred_h//2, pred_w, pred_h)\n",
    "                    tracker.init(frame, new_bbox)\n",
    "                else:\n",
    "                    status_lbl.config(text=\"Status: Lost Tracking\", fg=\"orange\")\n",
    "        \n",
    "        # Add info text\n",
    "        cv2.putText(frame, f\"Tracker: {tracker_type.get()}\", (10, 25), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "        cv2.putText(frame, f\"Kalman: {'Enabled' if use_kalman.get() else 'Disabled'}\", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "        \n",
    "        # Display the frame\n",
    "        img = ImageTk.PhotoImage(Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)))\n",
    "        video_lbl.imgtk = img\n",
    "        video_lbl.configure(image=img)\n",
    "    \n",
    "    win.after(15, update)\n",
    "\n",
    "# Controls frame\n",
    "frame = tk.Frame(win, bg=\"#2C3E50\")\n",
    "frame.pack(padx=10, pady=10)\n",
    "\n",
    "# First row controls\n",
    "tk.Label(frame, text=\"Select Tracker:\", font=(\"Arial\", 12, \"bold\"), fg=\"white\", bg=\"#2C3E50\").grid(row=0, column=0)\n",
    "ttk.Combobox(frame, textvariable=tracker_type, values=list(types.keys()), state=\"readonly\").grid(row=0, column=1, padx=5)\n",
    "tk.Button(frame, text=\"Select ROI\", width=12, command=select_roi, bg=\"#3498DB\", fg=\"white\", font=(\"Arial\", 10, \"bold\")).grid(row=0, column=2 , padx=5 , pady=5)\n",
    "tk.Button(frame, text=\"Start Tracking\", width=12, command=start, bg=\"#2ECC71\", fg=\"white\", font=(\"Arial\", 10, \"bold\")).grid(row=0, column=3 , padx=5, pady=5)\n",
    "tk.Button(frame, text=\"Stop Tracking\", width=12, command=stop, bg=\"#E74C3C\", fg=\"white\", font=(\"Arial\", 10, \"bold\")).grid(row=0, column=4 , padx=5, pady=5)\n",
    "tk.Button(frame, text=\"Reset Kalman\", width=12, command=reset_kalman, bg=\"#F39C12\", fg=\"white\", font=(\"Arial\", 10, \"bold\")).grid(row=0, column=5 , padx=5, pady=5)\n",
    "tk.Checkbutton(frame, text=\"Use Kalman Filter\", variable=use_kalman, onvalue=True, offvalue=False, bg=\"#2C3E50\", fg=\"white\", selectcolor=\"#2C3E50\", font=(\"Arial\", 10, \"bold\")).grid(row=0, column=6, padx=5)\n",
    "\n",
    "# Main loop\n",
    "update()\n",
    "win.mainloop()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try oop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "class ObjectTrackingApp:\n",
    "    def __init__(self, root):\n",
    "        # Initialize the main window\n",
    "        self.root = root\n",
    "        self.root.title(\"Enhanced Object Tracking\")\n",
    "        self.root.configure(bg=\"#101820\")\n",
    "        self.root.geometry(\"1100x600\")\n",
    "        \n",
    "        # Tracker options\n",
    "        self.tracker_types = {\n",
    "            \"MIL\": cv2.TrackerMIL_create, \n",
    "            \"KCF\": cv2.TrackerKCF_create, \n",
    "            \"CSRT\": cv2.TrackerCSRT_create\n",
    "        }\n",
    "        self.tracker_type = tk.StringVar(value=\"CSRT\")\n",
    "        \n",
    "        # Tracking enhancement options\n",
    "        self.use_optical_flow = tk.BooleanVar(value=True)\n",
    "        self.recovery_mode = tk.BooleanVar(value=True)\n",
    "        \n",
    "        # Tracking variables\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.tracker = None\n",
    "        self.bbox = None\n",
    "        self.tracking = False\n",
    "        self.prev_frame = None\n",
    "        self.prev_pts = None\n",
    "        self.tracking_history = []\n",
    "        self.recovery_frames = 0\n",
    "        self.max_recovery_frames = 30\n",
    "        \n",
    "        # Optical flow parameters\n",
    "        self.feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
    "        self.lk_params = dict(winSize=(15, 15), maxLevel=2, \n",
    "                         criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "        \n",
    "        # Create UI Elements\n",
    "        self._create_ui()\n",
    "        \n",
    "    def _create_ui(self):\n",
    "        # Video display label\n",
    "        self.video_lbl = tk.Label(self.root, bg=\"black\")\n",
    "        self.video_lbl.pack(fill=\"both\", expand=True, padx=10, pady=10)\n",
    "        \n",
    "        # Status label\n",
    "        self.status_lbl = tk.Label(self.root, text=\"Idle\", font=(\"Arial\", 15, \"bold\"), fg=\"white\", bg=\"#101820\")\n",
    "        self.status_lbl.pack(pady=5)\n",
    "        \n",
    "        # Controls frame\n",
    "        frame = tk.Frame(self.root, bg=\"#2C3E50\")\n",
    "        frame.pack(padx=10, pady=10)\n",
    "        \n",
    "        # Control elements\n",
    "        tk.Label(frame, text=\"Select Tracker:\", font=(\"Arial\", 12, \"bold\"), fg=\"white\", bg=\"#2C3E50\").grid(row=0, column=0, padx=5, pady=5)\n",
    "        ttk.Combobox(frame, textvariable=self.tracker_type, values=list(self.tracker_types.keys()), state=\"readonly\").grid(row=0, column=1, padx=5, pady=5)\n",
    "        tk.Button(frame, text=\"Select ROI\", width=12, command=self.select_roi, bg=\"#3498DB\", fg=\"white\", font=(\"Arial\", 10, \"bold\")).grid(row=0, column=2, padx=5, pady=5)\n",
    "        tk.Button(frame, text=\"Start Tracking\", width=12, command=self.start, bg=\"#2ECC71\", fg=\"white\", font=(\"Arial\", 10, \"bold\")).grid(row=0, column=3, padx=5, pady=5)\n",
    "        tk.Button(frame, text=\"Stop Tracking\", width=12, command=self.stop, bg=\"#E74C3C\", fg=\"white\", font=(\"Arial\", 10, \"bold\")).grid(row=0, column=4, padx=5, pady=5)\n",
    "        tk.Button(frame, text=\"Reset\", width=12, command=self.reset_tracker, bg=\"#F39C12\", fg=\"white\", font=(\"Arial\", 10, \"bold\")).grid(row=0, column=5, padx=5, pady=5)\n",
    "        tk.Checkbutton(frame, text=\"Use Optical Flow\", variable=self.use_optical_flow, fg=\"white\", bg=\"#2C3E50\", selectcolor=\"#3498DB\", font=(\"Arial\", 10)).grid(row=0, column=6, padx=15, pady=5)\n",
    "        tk.Checkbutton(frame, text=\"Auto Recovery Mode\", variable=self.recovery_mode, fg=\"white\", bg=\"#2C3E50\", selectcolor=\"#3498DB\", font=(\"Arial\", 10)).grid(row=0, column=7, padx=15, pady=5)\n",
    "    \n",
    "    def select_roi(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if ret:\n",
    "            cv2.putText(frame, \"Select ROI & press ESC\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            self.bbox = cv2.selectROI(\"Select ROI\", frame, fromCenter=False, showCrosshair=True)\n",
    "            cv2.destroyWindow(\"Select ROI\")\n",
    "            if self.bbox != (0, 0, 0, 0):\n",
    "                self.tracker = self.tracker_types[self.tracker_type.get()]()\n",
    "                self.tracker.init(frame, self.bbox)\n",
    "                self.tracking = True\n",
    "                self.status_lbl.config(text=\"Status: Tracking\", fg=\"lime\")\n",
    "                \n",
    "                # Initialize optical flow\n",
    "                self.prev_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "                x, y, w, h = map(int, self.bbox)\n",
    "                roi = self.prev_frame[y:y+h, x:x+w]\n",
    "                self.prev_pts = cv2.goodFeaturesToTrack(roi, mask=None, **self.feature_params)\n",
    "                if self.prev_pts is not None:\n",
    "                    self.prev_pts = self.prev_pts + np.array([x, y], dtype=np.float32)  # Adjust coordinates to global frame\n",
    "                self.tracking_history.clear()\n",
    "    \n",
    "    def start(self):\n",
    "        self.tracking = True\n",
    "        self.status_lbl.config(text=\"Status: Tracking\", fg=\"lime\")\n",
    "    \n",
    "    def stop(self):\n",
    "        self.tracking = False\n",
    "        self.status_lbl.config(text=\"Status: Stopped\", fg=\"red\")\n",
    "    \n",
    "    def reset_tracker(self):\n",
    "        self.tracking = False\n",
    "        self.tracker = None\n",
    "        self.bbox = None\n",
    "        self.prev_frame = None\n",
    "        self.prev_pts = None\n",
    "        self.tracking_history.clear()\n",
    "        self.recovery_frames = 0\n",
    "        self.status_lbl.config(text=\"Status: Reset\", fg=\"orange\")\n",
    "    \n",
    "    def update_tracker_with_optical_flow(self, frame, gray_frame):\n",
    "        if self.prev_frame is None or self.prev_pts is None or len(self.prev_pts) < 5:\n",
    "            return False, self.bbox\n",
    "        \n",
    "        # Calculate optical flow\n",
    "        next_pts, status, _ = cv2.calcOpticalFlowPyrLK(self.prev_frame, gray_frame, self.prev_pts, None, **self.lk_params)\n",
    "        \n",
    "        # Filter good points\n",
    "        if next_pts is not None:\n",
    "            good_new = next_pts[status == 1]\n",
    "            good_old = self.prev_pts[status == 1]\n",
    "            \n",
    "            if len(good_new) > 5:  # Enough points to estimate movement\n",
    "                # Calculate bounding box movement\n",
    "                movement = np.mean(good_new - good_old, axis=0)\n",
    "                x, y, w, h = self.bbox\n",
    "                \n",
    "                # Update bounding box position\n",
    "                new_x = x + movement[0]\n",
    "                new_y = y + movement[1]\n",
    "                \n",
    "                # Update previous points for next iteration\n",
    "                self.prev_pts = good_new.reshape(-1, 1, 2)\n",
    "                self.prev_frame = gray_frame.copy()\n",
    "                \n",
    "                # Update bbox\n",
    "                new_bbox = (new_x, new_y, w, h)\n",
    "                return True, new_bbox\n",
    "        \n",
    "        # Not enough points to track\n",
    "        return False, self.bbox\n",
    "    \n",
    "    def attempt_recovery(self, frame, gray_frame):\n",
    "        if len(self.tracking_history) < 5:\n",
    "            return False, self.bbox\n",
    "        \n",
    "        # Predict position based on recent movement\n",
    "        recent_positions = np.array(self.tracking_history[-5:])\n",
    "        if len(recent_positions) >= 2:\n",
    "            # Calculate average movement direction and speed\n",
    "            movements = recent_positions[1:] - recent_positions[:-1]\n",
    "            avg_movement = np.mean(movements, axis=0)\n",
    "            \n",
    "            # Predict new position\n",
    "            last_pos = recent_positions[-1]\n",
    "            predicted_pos = last_pos + avg_movement * (self.recovery_frames * 0.5 + 1)  # Scale movement by recovery time\n",
    "            \n",
    "            x, y, w, h = self.bbox\n",
    "            new_bbox = (predicted_pos[0], predicted_pos[1], w, h)\n",
    "            \n",
    "            # Reinitialize tracker at predicted position\n",
    "            self.tracker = self.tracker_types[self.tracker_type.get()]()\n",
    "            self.tracker.init(frame, new_bbox)\n",
    "            \n",
    "            self.recovery_frames += 1\n",
    "            return True, new_bbox\n",
    "        \n",
    "        return False, self.bbox\n",
    "    \n",
    "    def update(self):\n",
    "        ret, frame = self.cap.read()\n",
    "        if not ret:\n",
    "            self.root.after(15, self.update)\n",
    "            return\n",
    "        \n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        if self.tracking and self.tracker:\n",
    "            tracking_success = False\n",
    "            of_success = False\n",
    "            \n",
    "            # 1. Try CSRT tracker first\n",
    "            if self.tracker:\n",
    "                tracking_success, new_bbox = self.tracker.update(frame)\n",
    "            \n",
    "            # 2. Apply optical flow if enabled\n",
    "            if self.use_optical_flow.get():\n",
    "                of_success, of_bbox = self.update_tracker_with_optical_flow(frame, gray_frame)\n",
    "                \n",
    "                # Decide which result to use\n",
    "                if tracking_success and of_success:\n",
    "                    # Blend CSRT and optical flow results (weighted average)\n",
    "                    csrt_weight = 0.7\n",
    "                    of_weight = 0.3\n",
    "                    x1, y1, w1, h1 = new_bbox\n",
    "                    x2, y2, w2, h2 = of_bbox\n",
    "                    \n",
    "                    blended_x = x1 * csrt_weight + x2 * of_weight\n",
    "                    blended_y = y1 * csrt_weight + y2 * of_weight\n",
    "                    self.bbox = (blended_x, blended_y, w1, h1)  # Keep original width/height\n",
    "                    \n",
    "                    # Update optical flow points occasionally for long-term stability\n",
    "                    if len(self.tracking_history) % 10 == 0:\n",
    "                        x, y, w, h = map(int, self.bbox)\n",
    "                        roi = gray_frame[max(0, y):min(frame.shape[0], y+h), \n",
    "                                        max(0, x):min(frame.shape[1], x+w)]\n",
    "                        if roi.size > 0:\n",
    "                            pts = cv2.goodFeaturesToTrack(roi, mask=None, **self.feature_params)\n",
    "                            if pts is not None and pts.size > 0:\n",
    "                                self.prev_pts = pts + np.array([x, y], dtype=np.float32)\n",
    "                                self.prev_frame = gray_frame.copy()\n",
    "                elif tracking_success:\n",
    "                    self.bbox = new_bbox\n",
    "                elif of_success:\n",
    "                    self.bbox = of_bbox\n",
    "                    \n",
    "            elif tracking_success:\n",
    "                self.bbox = new_bbox\n",
    "            \n",
    "            # Store tracking history (for recovery)\n",
    "            if tracking_success or of_success:\n",
    "                x, y, w, h = map(float, self.bbox)\n",
    "                center_x, center_y = x + w/2, y + h/2\n",
    "                self.tracking_history.append((center_x, center_y))\n",
    "                if len(self.tracking_history) > 30:  # Keep last 30 positions\n",
    "                    self.tracking_history.pop(0)\n",
    "                \n",
    "                self.recovery_frames = 0\n",
    "                self.status_lbl.config(text=\"Status: Tracking\", fg=\"lime\")\n",
    "            \n",
    "            # Attempt recovery if tracking lost\n",
    "            elif self.recovery_mode.get() and self.recovery_frames < self.max_recovery_frames:\n",
    "                recovery_success, recovery_bbox = self.attempt_recovery(frame, gray_frame)\n",
    "                if recovery_success:\n",
    "                    self.bbox = recovery_bbox\n",
    "                    self.status_lbl.config(text=f\"Status: Recovering ({self.recovery_frames}/{self.max_recovery_frames})\", fg=\"orange\")\n",
    "                else:\n",
    "                    self.status_lbl.config(text=\"Status: Lost Tracking\", fg=\"red\")\n",
    "            else:\n",
    "                self.status_lbl.config(text=\"Status: Lost Tracking\", fg=\"red\")\n",
    "                \n",
    "            # Draw tracking information on frame\n",
    "            if self.bbox is not None:\n",
    "                x, y, w, h = map(int, self.bbox)\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "                \n",
    "                if tracking_success:\n",
    "                    label = \"Tracking (CSRT)\"\n",
    "                elif of_success:\n",
    "                    label = \"Tracking (OptFlow)\"\n",
    "                elif self.recovery_frames > 0:\n",
    "                    label = f\"Recovering ({self.recovery_frames})\"\n",
    "                else:\n",
    "                    label = \"Lost\"\n",
    "                    \n",
    "                cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "                \n",
    "                # Draw tracking history\n",
    "                if len(self.tracking_history) > 1:\n",
    "                    for i in range(1, len(self.tracking_history)):\n",
    "                        pt1 = tuple(map(int, self.tracking_history[i-1]))\n",
    "                        pt2 = tuple(map(int, self.tracking_history[i]))\n",
    "                        cv2.line(frame, pt1, pt2, (0, 0, 255), 1)\n",
    "        \n",
    "        # Display frame\n",
    "        img = ImageTk.PhotoImage(Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)))\n",
    "        self.video_lbl.imgtk = img\n",
    "        self.video_lbl.configure(image=img)\n",
    "        \n",
    "        self.root.after(33, self.update)\n",
    "    \n",
    "    def run(self):\n",
    "        # Start the update loop and run the application\n",
    "        self.update()\n",
    "        self.root.mainloop()\n",
    "    \n",
    "    def cleanup(self):\n",
    "        # Release resources\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Entry point\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = ObjectTrackingApp(root)\n",
    "    try:\n",
    "        app.run()\n",
    "    finally:\n",
    "        app.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### try!!!!!!\n",
    "\n",
    "##### Kalman Filter Prediction\n",
    "Adds motion prediction to handle temporary occlusions\n",
    "Smooths tracking trajectory to reduce jitter\n",
    "Provides position estimates when other tracking methods fail\n",
    "\n",
    "##### Template Matching\n",
    "Stores an image template of the tracked object, then searches for it when the primary tracker fails, helping re-identify the object after occlusion.\n",
    "\n",
    "##### Motion Detection\n",
    "Uses a background subtractor to detect moving objects in the region where the tracked object was last seen.\n",
    "\n",
    "##### Confidence Scoring\n",
    "Calculates and displays a confidence value for tracking quality, helping determine when to trust the tracker versus when to use recovery methods.\n",
    "\n",
    "##### Object Re-acquisition:\n",
    "Saves templates of the tracked object\n",
    "Uses template matching to relocate lost objects\n",
    "Implements a confidence threshold for reliable recovery\n",
    "\n",
    "##### Multi-method Fusion:\n",
    "Combines traditional trackers (CSRT, KCF, MIL) with optical flow and Kalman filtering\n",
    "Displays which tracking method is currently active\n",
    "Falls back gracefully between methods when occlusions occur"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VISION",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
